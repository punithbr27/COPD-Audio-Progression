{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3038c295",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import librosa.effects\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d93ad0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 1: Define Configuration, Paths, and Parameters ---\n",
    "\n",
    "# !!! IMPORTANT !!! -> Update these paths to match your system\n",
    "LABEL_PATH = \"/home/punith/Desktop/cHEAL 2.o/Labels.xlsx\"\n",
    "AUDIO_DIR = \"/home/punith/Desktop/cHEAL 2.o/RespiratoryDatabase@TR\"\n",
    "MODEL_SAVE_PATH = \"best_copd_model.keras\"\n",
    "\n",
    "# --- Parameters for feature extraction ---\n",
    "N_MELS = 128\n",
    "MAX_LEN = 150 # Max length of spectrogram time axis\n",
    "\n",
    "# --- Parameters for augmentation ---\n",
    "NOISE_FACTOR = 0.005\n",
    "TIME_SHIFT_MAX_SEC = 0.2\n",
    "PITCH_SHIFT_STEPS = 4\n",
    "TIME_STRETCH_RATE = 0.8 # Speed up by 1/0.8 = 1.25x\n",
    "\n",
    "# --- Parameters for training ---\n",
    "EPOCHS = 25 # Set to your desired number of epochs\n",
    "INITIAL_LEARNING_RATE = 0.001\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d37397e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Step 2: Define Helper Functions (Augmentation & Feature Extraction) ---\n",
    "\n",
    "def add_gaussian_noise(y, noise_factor=NOISE_FACTOR):\n",
    "    noise = np.random.randn(len(y))\n",
    "    augmented_data = y + noise_factor * noise\n",
    "    return augmented_data.astype(type(y[0]))\n",
    "\n",
    "def time_shift(y, sr, shift_max_sec=TIME_SHIFT_MAX_SEC):\n",
    "    shift_amount = int(sr * np.random.uniform(low=-shift_max_sec, high=shift_max_sec))\n",
    "    return np.roll(y, shift_amount)\n",
    "\n",
    "def extract_log_mel_spectrogram(y, sr):\n",
    "    \"\"\"Extracts a log-mel spectrogram and pads/truncates it to a fixed size.\"\"\"\n",
    "    mel_spec = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=N_MELS)\n",
    "    log_mel = librosa.power_to_db(mel_spec)\n",
    "    if log_mel.shape[1] < MAX_LEN:\n",
    "        pad_width = MAX_LEN - log_mel.shape[1]\n",
    "        log_mel = np.pad(log_mel, ((0, 0), (0, pad_width)), mode='constant')\n",
    "    else:\n",
    "        log_mel = log_mel[:, :MAX_LEN]\n",
    "    return log_mel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2d5f16e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Step 3: Loading and Preparing Data ---\n",
      "Total Patients: 11\n",
      "Training Patients: 8\n",
      "Testing Patients: 3\n",
      "\n",
      "--- Final Data Shapes ---\n",
      "X_train shape: (480, 128, 150, 1)\n",
      "y_train shape: (480,)\n",
      "X_test shape: (36, 128, 150, 1)\n",
      "y_test shape: (36,)\n"
     ]
    }
   ],
   "source": [
    "# --- Step 3: Load Data, Perform Patient-Aware Split, and Prepare for Training ---\n",
    "\n",
    "print(\"--- Step 3: Loading and Preparing Data ---\")\n",
    "df = pd.read_excel(LABEL_PATH)\n",
    "df_copd = df[df[\"Diagnosis\"].isin([\"COPD0\", \"COPD1\"])].copy()\n",
    "df_copd['label_encoded'] = df_copd['Diagnosis'].apply(lambda x: 0 if x == 'COPD0' else 1)\n",
    "label_dict = dict(zip(df_copd[\"Patient ID\"], df_copd[\"label_encoded\"]))\n",
    "patient_ids = list(label_dict.keys())\n",
    "\n",
    "# Patient-aware split to prevent data leakage\n",
    "train_pids, test_pids = train_test_split(patient_ids, test_size=0.25, random_state=42)\n",
    "print(f\"Total Patients: {len(patient_ids)}\")\n",
    "print(f\"Training Patients: {len(train_pids)}\")\n",
    "print(f\"Testing Patients: {len(test_pids)}\")\n",
    "\n",
    "# Process audio, augment, and create datasets\n",
    "X_train, y_train = [], []\n",
    "X_test, y_test = [], []\n",
    "\n",
    "for pid in patient_ids:\n",
    "    label = label_dict[pid]\n",
    "    is_training_patient = pid in train_pids\n",
    "    for side in ['L', 'R']:\n",
    "        for i in range(1, 7):\n",
    "            fname = f\"{pid}_{side}{i}.wav\"\n",
    "            fpath = os.path.join(AUDIO_DIR, fname)\n",
    "            if not os.path.exists(fpath): continue\n",
    "            \n",
    "            y_audio, sr = librosa.load(fpath, sr=None)\n",
    "            original_spec = extract_log_mel_spectrogram(y_audio, sr)\n",
    "            \n",
    "            if is_training_patient:\n",
    "                # Add original and 4 augmented versions for training data\n",
    "                X_train.extend([\n",
    "                    original_spec,\n",
    "                    extract_log_mel_spectrogram(add_gaussian_noise(y_audio), sr),\n",
    "                    extract_log_mel_spectrogram(time_shift(y_audio, sr), sr),\n",
    "                    extract_log_mel_spectrogram(librosa.effects.pitch_shift(y=y_audio, sr=sr, n_steps=PITCH_SHIFT_STEPS), sr),\n",
    "                    extract_log_mel_spectrogram(librosa.effects.time_stretch(y=y_audio, rate=1/TIME_STRETCH_RATE), sr)\n",
    "                ])\n",
    "                y_train.extend([label] * 5)\n",
    "            else:\n",
    "                # Only add original version for testing data\n",
    "                X_test.append(original_spec)\n",
    "                y_test.append(label)\n",
    "\n",
    "# Convert to numpy arrays and add channel dimension for CNN\n",
    "X_train = np.array(X_train)[..., np.newaxis]\n",
    "y_train = np.array(y_train)\n",
    "X_test = np.array(X_test)[..., np.newaxis]\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "print(\"\\n--- Final Data Shapes ---\")\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cd53b8d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Step 4: Handling Class Imbalance ---\n",
      "Labels in training data: 480 total\n",
      "Count of COPD0 (label 0): 300\n",
      "Count of COPD1 (label 1): 180\n",
      "Calculated Class Weights: {0: np.float64(0.8), 1: np.float64(1.3333333333333333)}\n",
      "The model will now penalize mistakes on the minority class more heavily.\n"
     ]
    }
   ],
   "source": [
    "# --- Step 4: Calculate Class Weights to Handle Imbalance ---\n",
    "\n",
    "print(\"\\n--- Step 4: Handling Class Imbalance ---\")\n",
    "# Calculate class weights\n",
    "class_weights_array = compute_class_weight(\n",
    "    'balanced',\n",
    "    classes=np.unique(y_train),\n",
    "    y=y_train\n",
    ")\n",
    "class_weights = dict(enumerate(class_weights_array))\n",
    "\n",
    "print(f\"Labels in training data: {len(y_train)} total\")\n",
    "print(f\"Count of COPD0 (label 0): {np.sum(y_train == 0)}\")\n",
    "print(f\"Count of COPD1 (label 1): {np.sum(y_train == 1)}\")\n",
    "print(f\"Calculated Class Weights: {class_weights}\")\n",
    "print(\"The model will now penalize mistakes on the minority class more heavily.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1ff789ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Step 5: Building the CNN Model ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_6\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_6\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_18          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_19          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_20          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36864</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">4,718,720</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_18 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m150\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_18          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m150\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_18 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_24 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_19 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_19          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_19 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m37\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_25 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m37\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_20 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m37\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_20          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m37\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_20 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_26 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_6 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36864\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │     \u001b[38;5;34m4,718,720\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_27 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m129\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,812,417</span> (18.36 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,812,417\u001b[0m (18.36 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,811,969</span> (18.36 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,811,969\u001b[0m (18.36 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> (1.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m448\u001b[0m (1.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Step 5: Build and Compile the CNN Model ---\n",
    "\n",
    "print(\"\\n--- Step 5: Building the CNN Model ---\")\n",
    "model = Sequential([\n",
    "    tf.keras.Input(shape=(N_MELS, MAX_LEN, 1)),\n",
    "    Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid') # Sigmoid for binary classification\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=INITIAL_LEARNING_RATE),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9fb5839d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Step 6: Starting Model Training for 25 Epochs ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 738ms/step - accuracy: 0.4514 - loss: 9.6973\n",
      "Epoch 1: val_accuracy improved from -inf to 0.33333, saving model to best_copd_model.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 777ms/step - accuracy: 0.4530 - loss: 9.4566 - val_accuracy: 0.3333 - val_loss: 8.3556 - learning_rate: 0.0010\n",
      "Epoch 2/25\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 730ms/step - accuracy: 0.6059 - loss: 1.1197\n",
      "Epoch 2: val_accuracy did not improve from 0.33333\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 742ms/step - accuracy: 0.6058 - loss: 1.1052 - val_accuracy: 0.3333 - val_loss: 13.9499 - learning_rate: 0.0010\n",
      "Epoch 3/25\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 744ms/step - accuracy: 0.6931 - loss: 0.6321\n",
      "Epoch 3: val_accuracy did not improve from 0.33333\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 758ms/step - accuracy: 0.6905 - loss: 0.6330 - val_accuracy: 0.3333 - val_loss: 8.1000 - learning_rate: 0.0010\n",
      "Epoch 4/25\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 752ms/step - accuracy: 0.6243 - loss: 0.6112\n",
      "Epoch 4: val_accuracy did not improve from 0.33333\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 764ms/step - accuracy: 0.6251 - loss: 0.6115 - val_accuracy: 0.3333 - val_loss: 5.9912 - learning_rate: 0.0010\n",
      "Epoch 5/25\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 735ms/step - accuracy: 0.6394 - loss: 0.6239\n",
      "Epoch 5: val_accuracy did not improve from 0.33333\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 746ms/step - accuracy: 0.6385 - loss: 0.6237 - val_accuracy: 0.3333 - val_loss: 4.8301 - learning_rate: 0.0010\n",
      "Epoch 6/25\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 743ms/step - accuracy: 0.6361 - loss: 0.6079\n",
      "Epoch 6: val_accuracy did not improve from 0.33333\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 755ms/step - accuracy: 0.6379 - loss: 0.6072 - val_accuracy: 0.3333 - val_loss: 4.0708 - learning_rate: 0.0010\n",
      "Epoch 7/25\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 737ms/step - accuracy: 0.6383 - loss: 0.5725\n",
      "Epoch 7: val_accuracy did not improve from 0.33333\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 749ms/step - accuracy: 0.6362 - loss: 0.5736 - val_accuracy: 0.3333 - val_loss: 3.3120 - learning_rate: 0.0010\n",
      "Epoch 8/25\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 735ms/step - accuracy: 0.6293 - loss: 0.5915\n",
      "Epoch 8: val_accuracy did not improve from 0.33333\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 747ms/step - accuracy: 0.6293 - loss: 0.5910 - val_accuracy: 0.3333 - val_loss: 2.8769 - learning_rate: 0.0010\n",
      "Epoch 9/25\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 761ms/step - accuracy: 0.7586 - loss: 0.5059\n",
      "Epoch 9: val_accuracy did not improve from 0.33333\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 774ms/step - accuracy: 0.7548 - loss: 0.5071 - val_accuracy: 0.3333 - val_loss: 5.8569 - learning_rate: 0.0010\n",
      "Epoch 10/25\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 743ms/step - accuracy: 0.7463 - loss: 0.5145\n",
      "Epoch 10: val_accuracy did not improve from 0.33333\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 755ms/step - accuracy: 0.7436 - loss: 0.5157 - val_accuracy: 0.3333 - val_loss: 2.1338 - learning_rate: 0.0010\n",
      "Epoch 11/25\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 744ms/step - accuracy: 0.7056 - loss: 0.5303\n",
      "Epoch 11: val_accuracy did not improve from 0.33333\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 756ms/step - accuracy: 0.7060 - loss: 0.5278 - val_accuracy: 0.3333 - val_loss: 1.5122 - learning_rate: 0.0010\n",
      "Epoch 12/25\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 755ms/step - accuracy: 0.7457 - loss: 0.4688\n",
      "Epoch 12: val_accuracy improved from 0.33333 to 0.50000, saving model to best_copd_model.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 784ms/step - accuracy: 0.7450 - loss: 0.4688 - val_accuracy: 0.5000 - val_loss: 0.9697 - learning_rate: 0.0010\n",
      "Epoch 13/25\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 739ms/step - accuracy: 0.8111 - loss: 0.3920\n",
      "Epoch 13: val_accuracy did not improve from 0.50000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 751ms/step - accuracy: 0.8080 - loss: 0.3949 - val_accuracy: 0.4722 - val_loss: 0.9959 - learning_rate: 0.0010\n",
      "Epoch 14/25\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 742ms/step - accuracy: 0.7672 - loss: 0.4096\n",
      "Epoch 14: val_accuracy did not improve from 0.50000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 754ms/step - accuracy: 0.7667 - loss: 0.4108 - val_accuracy: 0.3889 - val_loss: 0.8882 - learning_rate: 0.0010\n",
      "Epoch 15/25\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 761ms/step - accuracy: 0.7181 - loss: 0.4765\n",
      "Epoch 15: val_accuracy improved from 0.50000 to 0.52778, saving model to best_copd_model.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 788ms/step - accuracy: 0.7189 - loss: 0.4742 - val_accuracy: 0.5278 - val_loss: 0.8596 - learning_rate: 0.0010\n",
      "Epoch 16/25\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 743ms/step - accuracy: 0.7573 - loss: 0.4389\n",
      "Epoch 16: val_accuracy did not improve from 0.52778\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 754ms/step - accuracy: 0.7593 - loss: 0.4367 - val_accuracy: 0.4167 - val_loss: 0.9784 - learning_rate: 0.0010\n",
      "Epoch 17/25\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 745ms/step - accuracy: 0.8159 - loss: 0.4116\n",
      "Epoch 17: val_accuracy did not improve from 0.52778\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 757ms/step - accuracy: 0.8159 - loss: 0.4091 - val_accuracy: 0.4444 - val_loss: 1.0627 - learning_rate: 0.0010\n",
      "Epoch 18/25\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 766ms/step - accuracy: 0.7579 - loss: 0.3891\n",
      "Epoch 18: val_accuracy improved from 0.52778 to 0.58333, saving model to best_copd_model.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 800ms/step - accuracy: 0.7592 - loss: 0.3880 - val_accuracy: 0.5833 - val_loss: 0.7795 - learning_rate: 0.0010\n",
      "Epoch 19/25\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 741ms/step - accuracy: 0.8026 - loss: 0.3435\n",
      "Epoch 19: val_accuracy did not improve from 0.58333\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 753ms/step - accuracy: 0.8036 - loss: 0.3437 - val_accuracy: 0.4722 - val_loss: 0.9490 - learning_rate: 0.0010\n",
      "Epoch 20/25\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 747ms/step - accuracy: 0.7890 - loss: 0.3166\n",
      "Epoch 20: val_accuracy did not improve from 0.58333\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 760ms/step - accuracy: 0.7911 - loss: 0.3168 - val_accuracy: 0.4444 - val_loss: 0.8258 - learning_rate: 0.0010\n",
      "Epoch 21/25\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 767ms/step - accuracy: 0.8341 - loss: 0.3125\n",
      "Epoch 21: val_accuracy did not improve from 0.58333\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 779ms/step - accuracy: 0.8325 - loss: 0.3142 - val_accuracy: 0.5000 - val_loss: 0.8919 - learning_rate: 0.0010\n",
      "Epoch 22/25\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 742ms/step - accuracy: 0.8261 - loss: 0.3178\n",
      "Epoch 22: val_accuracy did not improve from 0.58333\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 754ms/step - accuracy: 0.8262 - loss: 0.3197 - val_accuracy: 0.5556 - val_loss: 0.7325 - learning_rate: 0.0010\n",
      "Epoch 23/25\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 744ms/step - accuracy: 0.8452 - loss: 0.3042\n",
      "Epoch 23: val_accuracy did not improve from 0.58333\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 757ms/step - accuracy: 0.8439 - loss: 0.3069 - val_accuracy: 0.3889 - val_loss: 1.2010 - learning_rate: 0.0010\n",
      "Epoch 24/25\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764ms/step - accuracy: 0.7899 - loss: 0.3422\n",
      "Epoch 24: val_accuracy did not improve from 0.58333\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 776ms/step - accuracy: 0.7905 - loss: 0.3418 - val_accuracy: 0.5000 - val_loss: 1.3413 - learning_rate: 0.0010\n",
      "Epoch 25/25\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 749ms/step - accuracy: 0.8199 - loss: 0.2935\n",
      "Epoch 25: val_accuracy improved from 0.58333 to 0.61111, saving model to best_copd_model.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 775ms/step - accuracy: 0.8202 - loss: 0.2943 - val_accuracy: 0.6111 - val_loss: 1.0006 - learning_rate: 0.0010\n",
      "Restoring model weights from the end of the best epoch: 22.\n"
     ]
    }
   ],
   "source": [
    "# --- Step 6: Define Callbacks and Train the Model ---\n",
    "\n",
    "# Define ALL callbacks for robust training\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True, verbose=1)\n",
    "model_checkpoint = ModelCheckpoint(MODEL_SAVE_PATH, save_best_only=True, monitor='val_accuracy', verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-6, verbose=1)\n",
    "\n",
    "print(f\"\\n--- Step 6: Starting Model Training for {EPOCHS} Epochs ---\")\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    callbacks=[early_stop, model_checkpoint, reduce_lr],\n",
    "    class_weight=class_weights # <-- Applying the calculated weights here\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5043b88a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Step 7: Evaluating Best Saved Model ---\n",
      "Loading best model from best_copd_model.keras for final evaluation.\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function TensorFlowTrainer._make_function.<locals>.multi_step_on_iterator at 0x7aac87353920> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      "Final Test Accuracy: 61.11%\n",
      "Final Test Loss: 1.0006\n"
     ]
    }
   ],
   "source": [
    "# --- Step 7: Evaluate the Final Model ---\n",
    "\n",
    "print(\"\\n--- Step 7: Evaluating Best Saved Model ---\")\n",
    "# The best model is already loaded thanks to `restore_best_weights=True` in EarlyStopping\n",
    "# Or we can explicitly load the one saved by ModelCheckpoint for certainty\n",
    "print(f\"Loading best model from {MODEL_SAVE_PATH} for final evaluation.\")\n",
    "model.load_weights(MODEL_SAVE_PATH)\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"\\nFinal Test Accuracy: {accuracy*100:.2f}%\")\n",
    "print(f\"Final Test Loss: {loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e06ddfb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 🩺 Starting Analysis for 'COPD1' Patients ---\n",
      "Found 5 patients with 'COPD1' diagnosis. Analyzing files...\n",
      "\n",
      "--- ✅ COPD1 Patient Confidence Score Results ---\n",
      "'Avg_Score' is the model's confidence in the 'COPD1' prediction (closer to 1.0 is more confident).\n",
      "Patients with LOW scores might be outliers or less severe cases.\n",
      "  Patient ID  Avg_Score  Audio_Files_Found\n",
      "0       H045   0.274511                 12\n",
      "1       H039   0.716988                 12\n",
      "2       H017   0.868227                 12\n",
      "3       H043   0.899407                 12\n",
      "4       H029   0.966138                 12\n",
      "\n",
      "--- 🩺 Starting Analysis for 'COPD0' Patients ---\n",
      "Found 6 patients with 'COPD0' diagnosis. Analyzing files...\n",
      "\n",
      "--- ⚠️ COPD0 Patient Risk Assessment Results ---\n",
      "'Avg_Score' is the predicted risk (similarity to COPD1). Higher scores indicate higher risk.\n",
      "High-scoring patients may warrant closer clinical observation.\n",
      "  Patient ID  Avg_Score  Audio_Files_Found\n",
      "0       H041   0.402531                 12\n",
      "1       H050   0.349982                 12\n",
      "2       H016   0.300926                 12\n",
      "3       H040   0.258690                 12\n",
      "4       H037   0.158253                 12\n",
      "5       H021   0.148619                 12\n"
     ]
    }
   ],
   "source": [
    "# --- Step 8: Analyze Patient Scores with the Trained Model ---\n",
    "\n",
    "def run_patient_analysis(trained_model, labels_path, audio_dir, target_diagnosis, sort_ascending):\n",
    "    \"\"\"\n",
    "    Analyzes all patients with a specific diagnosis, computes the average model\n",
    "    prediction score for their audio files, and returns a sorted DataFrame.\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- 🩺 Starting Analysis for '{target_diagnosis}' Patients ---\")\n",
    "    \n",
    "    df_labels = pd.read_excel(labels_path)\n",
    "    patient_ids = df_labels[df_labels['Diagnosis'] == target_diagnosis]['Patient ID'].tolist()\n",
    "    \n",
    "    if not patient_ids:\n",
    "        print(f\"No patients with diagnosis '{target_diagnosis}' found.\")\n",
    "        return None\n",
    "        \n",
    "    print(f\"Found {len(patient_ids)} patients with '{target_diagnosis}' diagnosis. Analyzing files...\")\n",
    "    \n",
    "    patient_predictions = {}\n",
    "    for pid in patient_ids:\n",
    "        scores = []\n",
    "        for side in ['L', 'R']:\n",
    "            for i in range(1, 7):\n",
    "                fname = f\"{pid}_{side}{i}.wav\"\n",
    "                fpath = os.path.join(audio_dir, fname)\n",
    "                \n",
    "                if not os.path.exists(fpath):\n",
    "                    continue\n",
    "\n",
    "                try:\n",
    "                    y_audio, sr = librosa.load(fpath, sr=None)\n",
    "                    log_mel_spec = extract_log_mel_spectrogram(y_audio, sr)\n",
    "                    \n",
    "                    model_input = np.expand_dims(log_mel_spec, axis=(0, -1)) # Combined expand_dims\n",
    "                    \n",
    "                    probability = trained_model.predict(model_input, verbose=0)[0][0]\n",
    "                    scores.append(probability)\n",
    "                except Exception as e:\n",
    "                    print(f\"Warning: Could not process file {fname}: {e}\")\n",
    "        # print(scores)\n",
    "        if scores:\n",
    "            patient_predictions[pid] = scores\n",
    "\n",
    "    results_list = []\n",
    "    for pid, scores in patient_predictions.items():\n",
    "        avg_score = np.mean(scores)\n",
    "        results_list.append({\n",
    "            'Patient ID': pid,\n",
    "            'Avg_Score': avg_score,\n",
    "            'Audio_Files_Found': len(scores)\n",
    "        })\n",
    "\n",
    "    if not results_list:\n",
    "        print(\"Could not generate any predictions.\")\n",
    "        return None\n",
    "\n",
    "    results_df = pd.DataFrame(results_list)\n",
    "    results_df = results_df.sort_values(by='Avg_Score', ascending=sort_ascending)\n",
    "    return results_df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "# --- Run the analysis for both groups ---\n",
    "\n",
    "# 1. Analyze COPD1 patients to see their confidence scores (high is good)\n",
    "# We sort ascending to see the patients the model is LEAST confident about first.\n",
    "copd1_confidence_df = run_patient_analysis(\n",
    "    trained_model=model,\n",
    "    labels_path=LABEL_PATH,\n",
    "    audio_dir=AUDIO_DIR,\n",
    "    target_diagnosis='COPD1',\n",
    "    sort_ascending=True\n",
    ")\n",
    "\n",
    "if copd1_confidence_df is not None:\n",
    "    print(\"\\n--- ✅ COPD1 Patient Confidence Score Results ---\")\n",
    "    print(\"'Avg_Score' is the model's confidence in the 'COPD1' prediction (closer to 1.0 is more confident).\")\n",
    "    print(\"Patients with LOW scores might be outliers or less severe cases.\")\n",
    "    print(copd1_confidence_df)\n",
    "\n",
    "# 2. Analyze COPD0 patients to see their risk scores (low is good)\n",
    "# We sort descending to see the \"healthy\" patients the model thinks are MOST at risk.\n",
    "copd0_risk_df = run_patient_analysis(\n",
    "    trained_model=model,\n",
    "    labels_path=LABEL_PATH,\n",
    "    audio_dir=AUDIO_DIR,\n",
    "    target_diagnosis='COPD0',\n",
    "    sort_ascending=False\n",
    ")\n",
    "\n",
    "if copd0_risk_df is not None:\n",
    "    print(\"\\n--- ⚠️ COPD0 Patient Risk Assessment Results ---\")\n",
    "    print(\"'Avg_Score' is the predicted risk (similarity to COPD1). Higher scores indicate higher risk.\")\n",
    "    print(\"High-scoring patients may warrant closer clinical observation.\")\n",
    "    print(copd0_risk_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf6d847",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3f5c09bc",
   "metadata": {},
   "source": [
    "Showing all 12 recording's prediction value and then averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9b94be15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # --- Step 8: Analyze Patient Scores with the Trained Model ---\n",
    "\n",
    "# def run_patient_analysis(trained_model, labels_path, audio_dir, target_diagnosis, sort_ascending):\n",
    "#     \"\"\"\n",
    "#     Analyzes all patients with a specific diagnosis, computes the average model\n",
    "#     prediction score for their audio files, and returns a sorted DataFrame.\n",
    "#     \"\"\"\n",
    "#     print(f\"\\n--- 🩺 Starting Analysis for '{target_diagnosis}' Patients ---\")\n",
    "    \n",
    "#     df_labels = pd.read_excel(labels_path)\n",
    "#     patient_ids = df_labels[df_labels['Diagnosis'] == target_diagnosis]['Patient ID'].tolist()\n",
    "    \n",
    "#     if not patient_ids:\n",
    "#         print(f\"No patients with diagnosis '{target_diagnosis}' found.\")\n",
    "#         return None\n",
    "        \n",
    "#     print(f\"Found {len(patient_ids)} patients with '{target_diagnosis}' diagnosis. Analyzing files...\")\n",
    "    \n",
    "#     patient_predictions = {}\n",
    "#     for pid in patient_ids:\n",
    "#         scores = []\n",
    "#         for side in ['L', 'R']:\n",
    "#             for i in range(1, 7):\n",
    "#                 fname = f\"{pid}_{side}{i}.wav\"\n",
    "#                 fpath = os.path.join(audio_dir, fname)\n",
    "                \n",
    "#                 if not os.path.exists(fpath):\n",
    "#                     continue\n",
    "\n",
    "#                 try:\n",
    "#                     y_audio, sr = librosa.load(fpath, sr=None)\n",
    "#                     log_mel_spec = extract_log_mel_spectrogram(y_audio, sr)\n",
    "                    \n",
    "#                     model_input = np.expand_dims(log_mel_spec, axis=(0, -1)) # Combined expand_dims\n",
    "                    \n",
    "#                     probability = trained_model.predict(model_input, verbose=0)[0][0]\n",
    "#                     scores.append(probability)\n",
    "#                 except Exception as e:\n",
    "#                     print(f\"Warning: Could not process file {fname}: {e}\")\n",
    "        \n",
    "#         # --- MODIFICATION START ---\n",
    "#         # If scores were collected for the patient, print them in the desired format\n",
    "#         # before adding them to the dictionary.\n",
    "#         if scores:\n",
    "#             # Create a list of scores formatted to 4 decimal places as strings\n",
    "#             formatted_scores = [f'{s:.4f}' for s in scores]\n",
    "#             print(f\"  -> Scores for Patient {pid}: {formatted_scores}\")\n",
    "            \n",
    "#             # Store the original float scores for calculation\n",
    "#             patient_predictions[pid] = scores\n",
    "#         # --- MODIFICATION END ---\n",
    "\n",
    "#     results_list = []\n",
    "#     for pid, scores in patient_predictions.items():\n",
    "#         avg_score = np.mean(scores)\n",
    "#         results_list.append({\n",
    "#             'Patient ID': pid,\n",
    "#             'Avg_Score': avg_score,\n",
    "#             'Audio_Files_Found': len(scores)\n",
    "#         })\n",
    "\n",
    "#     if not results_list:\n",
    "#         print(\"Could not generate any predictions.\")\n",
    "#         return None\n",
    "\n",
    "#     results_df = pd.DataFrame(results_list)\n",
    "#     results_df = results_df.sort_values(by='Avg_Score', ascending=sort_ascending)\n",
    "#     return results_df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "# # --- Run the analysis for both groups ---\n",
    "\n",
    "# # 1. Analyze COPD1 patients to see their confidence scores (high is good)\n",
    "# # We sort ascending to see the patients the model is LEAST confident about first.\n",
    "# copd1_confidence_df = run_patient_analysis(\n",
    "#     trained_model=model,\n",
    "#     labels_path=LABEL_PATH,\n",
    "#     audio_dir=AUDIO_DIR,\n",
    "#     target_diagnosis='COPD1',\n",
    "#     sort_ascending=True\n",
    "# )\n",
    "\n",
    "# if copd1_confidence_df is not None:\n",
    "#     print(\"\\n--- ✅ COPD1 Patient Confidence Score Results ---\")\n",
    "#     print(\"'Avg_Score' is the model's confidence in the 'COPD1' prediction (closer to 1.0 is more confident).\")\n",
    "#     print(\"Patients with LOW scores might be outliers or less severe cases.\")\n",
    "#     # Use to_string() to ensure the full table is printed without truncation\n",
    "#     print(copd1_confidence_df.to_string())\n",
    "\n",
    "# # 2. Analyze COPD0 patients to see their risk scores (low is good)\n",
    "# # We sort descending to see the \"healthy\" patients the model thinks are MOST at risk.\n",
    "# copd0_risk_df = run_patient_analysis(\n",
    "#     trained_model=model,\n",
    "#     labels_path=LABEL_PATH,\n",
    "#     audio_dir=AUDIO_DIR,\n",
    "#     target_diagnosis='COPD0',\n",
    "#     sort_ascending=False\n",
    "# )\n",
    "\n",
    "# if copd0_risk_df is not None:\n",
    "#     print(\"\\n--- ⚠️ COPD0 Patient Risk Assessment Results ---\")\n",
    "#     print(\"'Avg_Score' is the predicted risk (similarity to COPD1). Higher scores indicate higher risk.\")\n",
    "#     print(\"High-scoring patients may warrant closer clinical observation.\")\n",
    "#     # Use to_string() to ensure the full table is printed without truncation\n",
    "#     print(copd0_risk_df.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5c89dd29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 🩺 Starting Analysis for 'COPD1' Patients ---\n",
      "Found 5 patients with 'COPD1' diagnosis. Analyzing files...\n",
      "  -> Scores for Patient H017: ['0.9670', '0.5199', '0.9883', '1.0000', '0.7341', '0.5714', '0.9976', '0.9645', '0.9610', '1.0000', '0.8247', '0.8901']\n",
      "  -> Scores for Patient H029: ['0.9301', '0.9799', '0.9640', '0.9634', '0.9470', '0.9888', '0.9961', '0.9450', '0.9877', '0.9600', '0.9487', '0.9831']\n",
      "  -> Scores for Patient H039: ['0.5356', '0.2112', '0.9805', '1.0000', '0.9033', '1.0000', '0.5471', '0.5108', '0.9307', '0.9999', '0.4237', '0.5611']\n",
      "  -> Scores for Patient H043: ['0.9977', '0.9984', '0.9732', '0.8961', '0.5108', '0.9999', '0.9910', '0.9741', '0.9882', '0.9525', '0.5108', '1.0000']\n",
      "  -> Scores for Patient H045: ['0.4789', '0.2349', '0.0251', '0.2030', '0.0054', '0.2811', '0.5453', '0.5367', '0.0374', '0.8421', '0.0071', '0.0971']\n",
      "\n",
      "--- ✅ COPD1 Patient Confidence Score Results ---\n",
      "'Avg_Score' > 0.5 indicates the model correctly identified the patient.\n",
      "Patients with low scores might be outliers or less severe cases.\n",
      "  Patient ID  Avg_Score  Audio_Files_Found                                                  Assessment\n",
      "0       H045   0.274511                 12  ⚠️ Model Lacks Confidence (Possible miss / False Negative)\n",
      "1       H039   0.716988                 12            ✅ Model Confident (Correctly identified as COPD)\n",
      "2       H017   0.868227                 12            ✅ Model Confident (Correctly identified as COPD)\n",
      "3       H043   0.899407                 12            ✅ Model Confident (Correctly identified as COPD)\n",
      "4       H029   0.966138                 12            ✅ Model Confident (Correctly identified as COPD)\n",
      "\n",
      "--- 🩺 Starting Analysis for 'COPD0' Patients ---\n",
      "Found 6 patients with 'COPD0' diagnosis. Analyzing files...\n",
      "  -> Scores for Patient H016: ['0.0102', '0.4381', '0.2925', '0.5742', '0.0953', '0.3993', '0.0777', '0.2710', '0.0555', '0.7006', '0.5458', '0.1507']\n",
      "  -> Scores for Patient H021: ['0.0188', '0.0106', '0.0539', '0.3318', '0.3112', '0.3378', '0.0160', '0.0047', '0.3385', '0.0202', '0.3257', '0.0142']\n",
      "  -> Scores for Patient H037: ['0.0976', '0.0048', '0.0338', '0.1378', '0.0016', '0.9832', '0.0054', '0.0001', '0.0184', '0.0872', '0.0028', '0.5263']\n",
      "  -> Scores for Patient H040: ['0.0071', '0.0603', '0.4423', '0.1312', '0.0132', '1.0000', '0.3651', '0.1416', '0.3625', '0.1988', '0.0056', '0.3766']\n",
      "  -> Scores for Patient H041: ['0.0003', '0.0078', '0.2577', '0.3524', '1.0000', '0.1029', '0.0006', '0.0002', '0.1420', '0.9665', '1.0000', '0.9999']\n",
      "  -> Scores for Patient H050: ['0.2385', '0.5543', '0.4746', '0.0011', '0.0021', '0.0038', '0.0950', '0.9621', '0.7328', '0.9998', '0.1133', '0.0223']\n",
      "\n",
      "--- ⚠️ COPD0 Patient Risk Assessment Results ---\n",
      "'Avg_Score' > 0.5 indicates a healthy patient is flagged as being at risk.\n",
      "High-scoring patients may warrant closer clinical observation.\n",
      "  Patient ID  Avg_Score  Audio_Files_Found                          Assessment\n",
      "0       H041   0.402531                 12  ✅ Correctly Identified as Low-Risk\n",
      "1       H050   0.349982                 12  ✅ Correctly Identified as Low-Risk\n",
      "2       H016   0.300926                 12  ✅ Correctly Identified as Low-Risk\n",
      "3       H040   0.258690                 12  ✅ Correctly Identified as Low-Risk\n",
      "4       H037   0.158253                 12  ✅ Correctly Identified as Low-Risk\n",
      "5       H021   0.148619                 12  ✅ Correctly Identified as Low-Risk\n"
     ]
    }
   ],
   "source": [
    "# --- Step 8: Analyze Patient Scores and Provide Assessments ---\n",
    "\n",
    "def run_patient_analysis(trained_model, labels_path, audio_dir, target_diagnosis, sort_ascending):\n",
    "    \"\"\"\n",
    "    Analyzes all patients with a specific diagnosis, computes the average model\n",
    "    prediction score for their audio files, and returns a sorted DataFrame.\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- 🩺 Starting Analysis for '{target_diagnosis}' Patients ---\")\n",
    "    \n",
    "    df_labels = pd.read_excel(labels_path)\n",
    "    patient_ids = df_labels[df_labels['Diagnosis'] == target_diagnosis]['Patient ID'].tolist()\n",
    "    \n",
    "    if not patient_ids:\n",
    "        print(f\"No patients with diagnosis '{target_diagnosis}' found.\")\n",
    "        return None\n",
    "        \n",
    "    print(f\"Found {len(patient_ids)} patients with '{target_diagnosis}' diagnosis. Analyzing files...\")\n",
    "    \n",
    "    patient_predictions = {}\n",
    "    for pid in patient_ids:\n",
    "        scores = []\n",
    "        for side in ['L', 'R']:\n",
    "            for i in range(1, 7):\n",
    "                fname = f\"{pid}_{side}{i}.wav\"\n",
    "                fpath = os.path.join(audio_dir, fname)\n",
    "                \n",
    "                if not os.path.exists(fpath):\n",
    "                    continue\n",
    "\n",
    "                try:\n",
    "                    y_audio, sr = librosa.load(fpath, sr=None)\n",
    "                    log_mel_spec = extract_log_mel_spectrogram(y_audio, sr)\n",
    "                    \n",
    "                    model_input = np.expand_dims(log_mel_spec, axis=(0, -1))\n",
    "                    \n",
    "                    probability = trained_model.predict(model_input, verbose=0)[0][0]\n",
    "                    scores.append(probability)\n",
    "                except Exception as e:\n",
    "                    print(f\"Warning: Could not process file {fname}: {e}\")\n",
    "        \n",
    "        if scores:\n",
    "            formatted_scores = [f'{s:.4f}' for s in scores]\n",
    "            print(f\"  -> Scores for Patient {pid}: {formatted_scores}\")\n",
    "            patient_predictions[pid] = scores\n",
    "\n",
    "    results_list = []\n",
    "    for pid, scores in patient_predictions.items():\n",
    "        avg_score = np.mean(scores)\n",
    "        results_list.append({\n",
    "            'Patient ID': pid,\n",
    "            'Avg_Score': avg_score,\n",
    "            'Audio_Files_Found': len(scores)\n",
    "        })\n",
    "\n",
    "    if not results_list:\n",
    "        print(\"Could not generate any predictions.\")\n",
    "        return None\n",
    "\n",
    "    results_df = pd.DataFrame(results_list)\n",
    "    results_df = results_df.sort_values(by='Avg_Score', ascending=sort_ascending)\n",
    "    return results_df.reset_index(drop=True)\n",
    "\n",
    "# --- Define Assessment Functions ---\n",
    "\n",
    "def assess_copd1_patient(row):\n",
    "    \"\"\"Generates an assessment text for a patient known to have COPD1.\"\"\"\n",
    "    # A score >= 0.5 means the model correctly leans towards a COPD1 diagnosis.\n",
    "    if row['Avg_Score'] >= 0.5:\n",
    "        return \"✅ Model Confident (Correctly identified as COPD)\"\n",
    "    else:\n",
    "        return \"⚠️ Model Lacks Confidence (Possible miss / False Negative)\"\n",
    "\n",
    "def assess_copd0_patient(row):\n",
    "    \"\"\"Generates an assessment text for a healthy (COPD0) patient.\"\"\"\n",
    "    # A score < 0.5 means the model correctly leans towards a non-COPD diagnosis.\n",
    "    if row['Avg_Score'] < 0.5:\n",
    "        return \"✅ Correctly Identified as Low-Risk\"\n",
    "    else:\n",
    "        return \"⚠️ Flagged as High-Risk (Possible early signs / False Positive)\"\n",
    "\n",
    "# --- Run the analysis and apply assessments ---\n",
    "\n",
    "# 1. Analyze COPD1 patients \n",
    "copd1_confidence_df = run_patient_analysis(\n",
    "    trained_model=model,\n",
    "    labels_path=LABEL_PATH,\n",
    "    audio_dir=AUDIO_DIR,\n",
    "    target_diagnosis='COPD1',\n",
    "    sort_ascending=True  # Show least confident patients first\n",
    ")\n",
    "\n",
    "if copd1_confidence_df is not None:\n",
    "    # Add the new assessment column using the dedicated function\n",
    "    copd1_confidence_df['Assessment'] = copd1_confidence_df.apply(assess_copd1_patient, axis=1)\n",
    "    \n",
    "    print(\"\\n--- ✅ COPD1 Patient Confidence Score Results ---\")\n",
    "    print(\"'Avg_Score' > 0.5 indicates the model correctly identified the patient.\")\n",
    "    print(\"Patients with low scores might be outliers or less severe cases.\")\n",
    "    print(copd1_confidence_df.to_string())\n",
    "\n",
    "# 2. Analyze COPD0 patients\n",
    "copd0_risk_df = run_patient_analysis(\n",
    "    trained_model=model,\n",
    "    labels_path=LABEL_PATH,\n",
    "    audio_dir=AUDIO_DIR,\n",
    "    target_diagnosis='COPD0',\n",
    "    sort_ascending=False  # Show highest risk \"healthy\" patients first\n",
    ")\n",
    "\n",
    "if copd0_risk_df is not None:\n",
    "    # Add the new assessment column using the dedicated function\n",
    "    copd0_risk_df['Assessment'] = copd0_risk_df.apply(assess_copd0_patient, axis=1)\n",
    "\n",
    "    print(\"\\n--- ⚠️ COPD0 Patient Risk Assessment Results ---\")\n",
    "    print(\"'Avg_Score' > 0.5 indicates a healthy patient is flagged as being at risk.\")\n",
    "    print(\"High-scoring patients may warrant closer clinical observation.\")\n",
    "    print(copd0_risk_df.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00f3d71",
   "metadata": {},
   "source": [
    "Showing all 12 recording's prediction value and then counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "957ad31d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 🗳️ Starting Analysis for 'COPD1' Patients (Majority Vote Method) ---\n",
      "Found 5 patients with 'COPD1' diagnosis. Counting votes for each file...\n",
      "  -> Raw Scores for Patient H017: ['0.9670', '0.5199', '0.9883', '1.0000', '0.7341', '0.5714', '0.9976', '0.9645', '0.9610', '1.0000', '0.8247', '0.8901']\n",
      "  -> Raw Scores for Patient H029: ['0.9301', '0.9799', '0.9640', '0.9634', '0.9470', '0.9888', '0.9961', '0.9450', '0.9877', '0.9600', '0.9487', '0.9831']\n",
      "  -> Raw Scores for Patient H039: ['0.5356', '0.2112', '0.9805', '1.0000', '0.9033', '1.0000', '0.5471', '0.5108', '0.9307', '0.9999', '0.4237', '0.5611']\n",
      "  -> Raw Scores for Patient H043: ['0.9977', '0.9984', '0.9732', '0.8961', '0.5108', '0.9999', '0.9910', '0.9741', '0.9882', '0.9525', '0.5108', '1.0000']\n",
      "  -> Raw Scores for Patient H045: ['0.4789', '0.2349', '0.0251', '0.2030', '0.0054', '0.2811', '0.5453', '0.5367', '0.0374', '0.8421', '0.0071', '0.0971']\n",
      "\n",
      "--- ✅ COPD1 Patient Majority Vote Results ---\n",
      "This table shows if the model's majority vote matched the patient's actual 'COPD1' diagnosis.\n",
      "  Patient ID  COPD1_Votes  COPD0_Votes  Total_Files Final_Prediction                                    Assessment\n",
      "0       H045            3            9           12            COPD0  ❌ Incorrect (Predicted COPD0, but was COPD1)\n",
      "1       H039           10            2           12            COPD1                   ✅ Correct (Predicted COPD1)\n",
      "2       H029           12            0           12            COPD1                   ✅ Correct (Predicted COPD1)\n",
      "3       H017           12            0           12            COPD1                   ✅ Correct (Predicted COPD1)\n",
      "4       H043           12            0           12            COPD1                   ✅ Correct (Predicted COPD1)\n",
      "\n",
      "--- 🗳️ Starting Analysis for 'COPD0' Patients (Majority Vote Method) ---\n",
      "Found 6 patients with 'COPD0' diagnosis. Counting votes for each file...\n",
      "  -> Raw Scores for Patient H016: ['0.0102', '0.4381', '0.2925', '0.5742', '0.0953', '0.3993', '0.0777', '0.2710', '0.0555', '0.7006', '0.5458', '0.1507']\n",
      "  -> Raw Scores for Patient H021: ['0.0188', '0.0106', '0.0539', '0.3318', '0.3112', '0.3378', '0.0160', '0.0047', '0.3385', '0.0202', '0.3257', '0.0142']\n",
      "  -> Raw Scores for Patient H037: ['0.0976', '0.0048', '0.0338', '0.1378', '0.0016', '0.9832', '0.0054', '0.0001', '0.0184', '0.0872', '0.0028', '0.5263']\n",
      "  -> Raw Scores for Patient H040: ['0.0071', '0.0603', '0.4423', '0.1312', '0.0132', '1.0000', '0.3651', '0.1416', '0.3625', '0.1988', '0.0056', '0.3766']\n",
      "  -> Raw Scores for Patient H041: ['0.0003', '0.0078', '0.2577', '0.3524', '1.0000', '0.1029', '0.0006', '0.0002', '0.1420', '0.9665', '1.0000', '0.9999']\n",
      "  -> Raw Scores for Patient H050: ['0.2385', '0.5543', '0.4746', '0.0011', '0.0021', '0.0038', '0.0950', '0.9621', '0.7328', '0.9998', '0.1133', '0.0223']\n",
      "\n",
      "--- ⚠️ COPD0 Patient Majority Vote Results ---\n",
      "This table shows if the model incorrectly flagged a healthy patient based on a majority vote.\n",
      "Incorrect '❌' assessments here are potential False Positives.\n",
      "  Patient ID  COPD1_Votes  COPD0_Votes  Total_Files Final_Prediction                   Assessment\n",
      "0       H041            4            8           12            COPD0  ✅ Correct (Predicted COPD0)\n",
      "1       H050            4            8           12            COPD0  ✅ Correct (Predicted COPD0)\n",
      "2       H016            3            9           12            COPD0  ✅ Correct (Predicted COPD0)\n",
      "3       H037            2           10           12            COPD0  ✅ Correct (Predicted COPD0)\n",
      "4       H040            1           11           12            COPD0  ✅ Correct (Predicted COPD0)\n",
      "5       H021            0           12           12            COPD0  ✅ Correct (Predicted COPD0)\n"
     ]
    }
   ],
   "source": [
    "# --- Step 8 (Alternative): Analyze Patient Scores by Majority Vote ---\n",
    "\n",
    "def run_patient_analysis_by_vote(trained_model, labels_path, audio_dir, target_diagnosis, sort_ascending):\n",
    "    \"\"\"\n",
    "    Analyzes patients using a majority vote method. For each patient, it counts\n",
    "    the number of audio files predicted as COPD1 vs COPD0 and determines the\n",
    "    final prediction based on the majority.\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- 🗳️ Starting Analysis for '{target_diagnosis}' Patients (Majority Vote Method) ---\")\n",
    "    \n",
    "    df_labels = pd.read_excel(labels_path)\n",
    "    patient_ids = df_labels[df_labels['Diagnosis'] == target_diagnosis]['Patient ID'].tolist()\n",
    "    \n",
    "    if not patient_ids:\n",
    "        print(f\"No patients with diagnosis '{target_diagnosis}' found.\")\n",
    "        return None\n",
    "        \n",
    "    print(f\"Found {len(patient_ids)} patients with '{target_diagnosis}' diagnosis. Counting votes for each file...\")\n",
    "    \n",
    "    patient_scores_data = {}\n",
    "    for pid in patient_ids:\n",
    "        scores = []\n",
    "        for side in ['L', 'R']:\n",
    "            for i in range(1, 7):\n",
    "                fname = f\"{pid}_{side}{i}.wav\"\n",
    "                fpath = os.path.join(audio_dir, fname)\n",
    "                \n",
    "                if not os.path.exists(fpath): continue\n",
    "\n",
    "                try:\n",
    "                    y_audio, sr = librosa.load(fpath, sr=None)\n",
    "                    log_mel_spec = extract_log_mel_spectrogram(y_audio, sr)\n",
    "                    model_input = np.expand_dims(log_mel_spec, axis=(0, -1))\n",
    "                    probability = trained_model.predict(model_input, verbose=0)[0][0]\n",
    "                    scores.append(probability)\n",
    "                except Exception as e:\n",
    "                    print(f\"Warning: Could not process file {fname}: {e}\")\n",
    "        \n",
    "        if scores:\n",
    "            formatted_scores = [f'{s:.4f}' for s in scores]\n",
    "            print(f\"  -> Raw Scores for Patient {pid}: {formatted_scores}\")\n",
    "            patient_scores_data[pid] = scores\n",
    "\n",
    "    results_list = []\n",
    "    for pid, scores in patient_scores_data.items():\n",
    "        # --- COUNTING LOGIC ---\n",
    "        copd1_votes = sum(1 for s in scores if s >= 0.5)\n",
    "        total_files = len(scores)\n",
    "        copd0_votes = total_files - copd1_votes\n",
    "        \n",
    "        # Determine the final prediction by majority\n",
    "        if copd1_votes > copd0_votes:\n",
    "            final_prediction = 'COPD1'\n",
    "        else:\n",
    "            final_prediction = 'COPD0' # Default to COPD0 in case of a tie\n",
    "            \n",
    "        results_list.append({\n",
    "            'Patient ID': pid,\n",
    "            'COPD1_Votes': copd1_votes,\n",
    "            'COPD0_Votes': copd0_votes,\n",
    "            'Total_Files': total_files,\n",
    "            'Final_Prediction': final_prediction\n",
    "        })\n",
    "\n",
    "    if not results_list:\n",
    "        print(\"Could not generate any predictions.\")\n",
    "        return None\n",
    "\n",
    "    results_df = pd.DataFrame(results_list)\n",
    "    # Sort by the number of COPD1 votes to find the most/least severe cases\n",
    "    results_df = results_df.sort_values(by='COPD1_Votes', ascending=sort_ascending)\n",
    "    return results_df.reset_index(drop=True)\n",
    "\n",
    "def assess_prediction_vs_truth(row, true_label):\n",
    "    \"\"\"Generates an assessment comparing the majority vote prediction to the known truth.\"\"\"\n",
    "    if row['Final_Prediction'] == true_label:\n",
    "        return f\"✅ Correct (Predicted {row['Final_Prediction']})\"\n",
    "    else:\n",
    "        return f\"❌ Incorrect (Predicted {row['Final_Prediction']}, but was {true_label})\"\n",
    "\n",
    "# --- Run the analysis using the counting method ---\n",
    "\n",
    "# 1. Analyze COPD1 patients\n",
    "copd1_vote_df = run_patient_analysis_by_vote(\n",
    "    trained_model=model,\n",
    "    labels_path=LABEL_PATH,\n",
    "    audio_dir=AUDIO_DIR,\n",
    "    target_diagnosis='COPD1',\n",
    "    sort_ascending=True  # Show patients with the FEWEST COPD1 votes first\n",
    ")\n",
    "\n",
    "if copd1_vote_df is not None:\n",
    "    copd1_vote_df['Assessment'] = copd1_vote_df.apply(assess_prediction_vs_truth, true_label='COPD1', axis=1)\n",
    "    \n",
    "    print(\"\\n--- ✅ COPD1 Patient Majority Vote Results ---\")\n",
    "    print(\"This table shows if the model's majority vote matched the patient's actual 'COPD1' diagnosis.\")\n",
    "    print(copd1_vote_df.to_string())\n",
    "\n",
    "# 2. Analyze COPD0 patients\n",
    "copd0_vote_df = run_patient_analysis_by_vote(\n",
    "    trained_model=model,\n",
    "    labels_path=LABEL_PATH,\n",
    "    audio_dir=AUDIO_DIR,\n",
    "    target_diagnosis='COPD0',\n",
    "    sort_ascending=False  # Show healthy patients with the MOST COPD1 votes first\n",
    ")\n",
    "\n",
    "if copd0_vote_df is not None:\n",
    "    copd0_vote_df['Assessment'] = copd0_vote_df.apply(assess_prediction_vs_truth, true_label='COPD0', axis=1)\n",
    "\n",
    "    print(\"\\n--- ⚠️ COPD0 Patient Majority Vote Results ---\")\n",
    "    print(\"This table shows if the model incorrectly flagged a healthy patient based on a majority vote.\")\n",
    "    print(\"Incorrect '❌' assessments here are potential False Positives.\")\n",
    "    print(copd0_vote_df.to_string())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "audio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
