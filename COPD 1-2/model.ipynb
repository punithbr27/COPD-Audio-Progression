{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "03d1ac92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Step 3: Loading and Validating Data for COPD 1 vs 2 ---\n",
      "\n",
      "Performing stratified patient-aware split...\n",
      "Total Patients: 12, Training PIDs: 9, Testing PIDs: 3\n",
      "\n",
      "--- Final Data Shapes ---\n",
      " X_train: (540, 128, 150, 1), y_train: (540,)\n",
      " X_test: (36, 128, 150, 1), y_test: (36,)\n",
      "\n",
      "--- Step 4: Handling Class Imbalance for 1 vs 2 ---\n",
      "Counts: COPD1(0)=240, COPD2(1)=300\n",
      "Calculated Weights: {0: np.float64(1.125), 1: np.float64(0.9)}\n",
      "\n",
      "--- Step 5: Building the CNN Model for 1-2 Progression ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-30 16:03:25.904082: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36864</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">4,718,720</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m150\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m150\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m37\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m37\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m37\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m37\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36864\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │     \u001b[38;5;34m4,718,720\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m129\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,812,417</span> (18.36 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,812,417\u001b[0m (18.36 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,811,969</span> (18.36 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,811,969\u001b[0m (18.36 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> (1.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m448\u001b[0m (1.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import librosa.effects\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "# --- Step 1: Configuration & Parameters ---\n",
    "LABEL_PATH_1_2 = \"/home/punith/Desktop/cHEAL 2.o/Labels.xlsx\"\n",
    "AUDIO_DIR_1_2 = \"/home/punith/Desktop/cHEAL 2.o/RespiratoryDatabase@TR\"\n",
    "MODEL_SAVE_PATH_1_2 = \"best_copd_1_2_model.keras\"\n",
    "\n",
    "N_MELS, MAX_LEN, EPOCHS, BATCH_SIZE = 128, 150, 25, 32\n",
    "NOISE_FACTOR, TIME_SHIFT_MAX_SEC, PITCH_SHIFT_STEPS, TIME_STRETCH_RATE = 0.005, 0.2, 4, 0.8\n",
    "INITIAL_LEARNING_RATE = 0.001\n",
    "\n",
    "\n",
    "# --- Step 2: Helper Functions ---\n",
    "def add_gaussian_noise(y, noise_factor=NOISE_FACTOR):\n",
    "    return y + noise_factor * np.random.randn(len(y))\n",
    "\n",
    "def time_shift(y, sr, shift_max_sec=TIME_SHIFT_MAX_SEC):\n",
    "    return np.roll(y, int(sr*np.random.uniform(-shift_max_sec, shift_max_sec)))\n",
    "\n",
    "def extract_log_mel_spectrogram(y, sr):\n",
    "    mel_spec = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=N_MELS)\n",
    "    log_mel = librosa.power_to_db(mel_spec)\n",
    "    if log_mel.shape[1] < MAX_LEN:\n",
    "        log_mel = np.pad(log_mel, ((0, 0), (0, MAX_LEN - log_mel.shape[1])), mode='constant')\n",
    "    else:\n",
    "        log_mel = log_mel[:, :MAX_LEN]\n",
    "    return log_mel\n",
    "\n",
    "\n",
    "# --- Step 3: Load Data with Final Validation ---\n",
    "print(\"--- Step 3: Loading and Validating Data for COPD 1 vs 2 ---\")\n",
    "df = pd.read_excel(LABEL_PATH_1_2)\n",
    "df_copd_1_2 = df[df[\"Diagnosis\"].isin([\"COPD1\", \"COPD2\"])].copy()\n",
    "\n",
    "if df_copd_1_2['Diagnosis'].nunique() < 2:\n",
    "    raise ValueError(\"The Excel file must contain patients from both 'COPD1' and 'COPD2' diagnoses.\")\n",
    "\n",
    "df_copd_1_2['label_encoded'] = df_copd_1_2['Diagnosis'].apply(lambda x: 0 if x == 'COPD1' else 1)\n",
    "label_dict_1_2 = dict(zip(df_copd_1_2[\"Patient ID\"], df_copd_1_2[\"label_encoded\"]))\n",
    "patient_ids_1_2 = list(label_dict_1_2.keys())\n",
    "patient_labels_1_2 = list(label_dict_1_2.values())\n",
    "\n",
    "print(\"\\nPerforming stratified patient-aware split...\")\n",
    "try:\n",
    "    train_pids, test_pids, _, _ = train_test_split(\n",
    "        patient_ids_1_2, patient_labels_1_2,\n",
    "        test_size=0.25, random_state=42, stratify=patient_labels_1_2\n",
    "    )\n",
    "except ValueError as e:\n",
    "    print(f\"\\nFATAL ERROR during train/test split: {e}\")\n",
    "    print(\"This usually means one class has only 1 patient, making stratification impossible.\")\n",
    "    raise\n",
    "\n",
    "print(f\"Total Patients: {len(patient_ids_1_2)}, Training PIDs: {len(train_pids)}, Testing PIDs: {len(test_pids)}\")\n",
    "\n",
    "X_train, y_train, X_test, y_test = [], [], [], []\n",
    "for pid in patient_ids_1_2:\n",
    "    label = label_dict_1_2[pid]\n",
    "    is_training_patient = pid in train_pids\n",
    "    for side in ['L', 'R']:\n",
    "        for i in range(1, 7):\n",
    "            fname = f\"{pid}_{side}{i}.wav\"\n",
    "            fpath = os.path.join(AUDIO_DIR_1_2, fname)\n",
    "            if not os.path.exists(fpath): continue\n",
    "            try:\n",
    "                y_audio, sr = librosa.load(fpath, sr=None)\n",
    "                spec = extract_log_mel_spectrogram(y_audio, sr)\n",
    "                if is_training_patient:\n",
    "                    y_train.extend([label] * 5)\n",
    "                    X_train.extend([\n",
    "                        spec, extract_log_mel_spectrogram(add_gaussian_noise(y_audio, sr), sr),\n",
    "                        extract_log_mel_spectrogram(time_shift(y_audio, sr), sr),\n",
    "                        extract_log_mel_spectrogram(librosa.effects.pitch_shift(y=y_audio, sr=sr, n_steps=4), sr),\n",
    "                        extract_log_mel_spectrogram(librosa.effects.time_stretch(y=y_audio, rate=1/TIME_STRETCH_RATE), sr)\n",
    "                    ])\n",
    "                elif pid in test_pids:\n",
    "                    X_test.append(spec)\n",
    "                    y_test.append(label)\n",
    "            except Exception as e:\n",
    "                print(f\"Warning: Error processing {fname}: {e}\")\n",
    "\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "X_test, y_test = np.array(X_test), np.array(y_test)\n",
    "\n",
    "# --- FINAL VALIDATION BLOCK (The definitive fix) ---\n",
    "if len(np.unique(y_train)) < 2:\n",
    "    raise ValueError(\n",
    "        \"\\n\\nFATAL ERROR: The training set ('y_train') ended up with only one class.\\n\"\n",
    "        \"This happens because audio files for the other class are MISSING from the directory.\\n\\n\"\n",
    "        f\"Training was attempted with these Patient IDs: {train_pids}\\n\\n\"\n",
    "        \"ACTION REQUIRED: Please verify that the audio files for ALL of these patients actually exist in this folder:\\n\"\n",
    "        f\"-> {AUDIO_DIR_1_2}\\n\"\n",
    "    )\n",
    "\n",
    "X_train = X_train[..., np.newaxis]\n",
    "X_test = X_test[..., np.newaxis]\n",
    "print(\"\\n--- Final Data Shapes ---\\n\", f\"X_train: {X_train.shape}, y_train: {y_train.shape}\\n\", f\"X_test: {X_test.shape}, y_test: {y_test.shape}\")\n",
    "\n",
    "# --- Step 4: Calculate Class Weights for 1 vs 2 ---\n",
    "print(\"\\n--- Step 4: Handling Class Imbalance for 1 vs 2 ---\")\n",
    "class_weights_array = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weights_1_2 = dict(enumerate(class_weights_array))\n",
    "print(f\"Counts: COPD1(0)={np.sum(y_train == 0)}, COPD2(1)={np.sum(y_train == 1)}\")\n",
    "print(f\"Calculated Weights: {class_weights_1_2}\")\n",
    "\n",
    "\n",
    "# --- Step 5: Build the CNN Model ---\n",
    "print(\"\\n--- Step 5: Building the CNN Model for 1-2 Progression ---\")\n",
    "model_1_2 = Sequential([\n",
    "    tf.keras.Input(shape=(N_MELS, MAX_LEN, 1)),\n",
    "    Conv2D(32, (3, 3), activation='relu', padding='same'), BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=(2, 2)), Dropout(0.3),\n",
    "    Conv2D(64, (3, 3), activation='relu', padding='same'), BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=(2, 2)), Dropout(0.3),\n",
    "    Conv2D(128, (3, 3), activation='relu', padding='same'), BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=(2, 2)), Dropout(0.3),\n",
    "    Flatten(), Dense(128, activation='relu'), Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "model_1_2.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=INITIAL_LEARNING_RATE), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model_1_2.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3a63ee3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Step 6: Starting Model Training for COPD 1-2 ---\n",
      "\n",
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-30 16:03:39.613513: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 78643200 exceeds 10% of free system memory.\n",
      "2025-06-30 16:03:39.664811: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 78643200 exceeds 10% of free system memory.\n",
      "2025-06-30 16:03:39.706835: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 78643200 exceeds 10% of free system memory.\n",
      "2025-06-30 16:03:40.371572: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 78643200 exceeds 10% of free system memory.\n",
      "2025-06-30 16:03:40.371627: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 78643200 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 778ms/step - accuracy: 0.5472 - loss: 10.4778\n",
      "Epoch 1: val_accuracy improved from -inf to 0.33333, saving model to best_copd_1_2_model.keras\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 813ms/step - accuracy: 0.5463 - loss: 10.3755 - val_accuracy: 0.3333 - val_loss: 5.3143 - learning_rate: 0.0010\n",
      "Epoch 2/25\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 739ms/step - accuracy: 0.4847 - loss: 3.8411\n",
      "Epoch 2: val_accuracy improved from 0.33333 to 0.66667, saving model to best_copd_1_2_model.keras\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 766ms/step - accuracy: 0.4870 - loss: 3.8005 - val_accuracy: 0.6667 - val_loss: 1.0821 - learning_rate: 0.0010\n",
      "Epoch 3/25\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 742ms/step - accuracy: 0.4820 - loss: 1.7950\n",
      "Epoch 3: val_accuracy did not improve from 0.66667\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 754ms/step - accuracy: 0.4826 - loss: 1.7864 - val_accuracy: 0.6667 - val_loss: 0.8145 - learning_rate: 0.0010\n",
      "Epoch 4/25\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 745ms/step - accuracy: 0.4926 - loss: 0.7340\n",
      "Epoch 4: val_accuracy did not improve from 0.66667\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 757ms/step - accuracy: 0.4936 - loss: 0.7334 - val_accuracy: 0.4167 - val_loss: 0.7142 - learning_rate: 0.0010\n",
      "Epoch 5/25\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 743ms/step - accuracy: 0.5031 - loss: 0.7242\n",
      "Epoch 5: val_accuracy did not improve from 0.66667\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 754ms/step - accuracy: 0.5049 - loss: 0.7236 - val_accuracy: 0.6667 - val_loss: 0.6449 - learning_rate: 0.0010\n",
      "Epoch 6/25\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 717ms/step - accuracy: 0.5010 - loss: 0.6829\n",
      "Epoch 6: val_accuracy did not improve from 0.66667\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 727ms/step - accuracy: 0.5011 - loss: 0.6827 - val_accuracy: 0.5000 - val_loss: 0.7013 - learning_rate: 0.0010\n",
      "Epoch 7/25\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 712ms/step - accuracy: 0.5472 - loss: 0.6839\n",
      "Epoch 7: val_accuracy did not improve from 0.66667\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 723ms/step - accuracy: 0.5464 - loss: 0.6849 - val_accuracy: 0.3611 - val_loss: 0.7623 - learning_rate: 0.0010\n",
      "Epoch 8/25\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 716ms/step - accuracy: 0.5570 - loss: 0.6971\n",
      "Epoch 8: val_accuracy did not improve from 0.66667\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 727ms/step - accuracy: 0.5563 - loss: 0.6959 - val_accuracy: 0.6389 - val_loss: 1.0435 - learning_rate: 0.0010\n",
      "Epoch 9/25\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 723ms/step - accuracy: 0.5179 - loss: 0.6826\n",
      "Epoch 9: val_accuracy did not improve from 0.66667\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 733ms/step - accuracy: 0.5189 - loss: 0.6807 - val_accuracy: 0.6111 - val_loss: 1.0139 - learning_rate: 0.0010\n",
      "Epoch 10/25\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 735ms/step - accuracy: 0.5745 - loss: 0.6447\n",
      "Epoch 10: val_accuracy did not improve from 0.66667\n",
      "\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 746ms/step - accuracy: 0.5737 - loss: 0.6443 - val_accuracy: 0.4444 - val_loss: 1.3252 - learning_rate: 0.0010\n",
      "Epoch 11/25\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 728ms/step - accuracy: 0.5516 - loss: 0.6070\n",
      "Epoch 11: val_accuracy did not improve from 0.66667\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 739ms/step - accuracy: 0.5527 - loss: 0.6067 - val_accuracy: 0.5278 - val_loss: 1.2069 - learning_rate: 2.0000e-04\n",
      "Epoch 12/25\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 719ms/step - accuracy: 0.5685 - loss: 0.5799\n",
      "Epoch 12: val_accuracy did not improve from 0.66667\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 729ms/step - accuracy: 0.5695 - loss: 0.5800 - val_accuracy: 0.5278 - val_loss: 1.2414 - learning_rate: 2.0000e-04\n",
      "Epoch 13/25\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 738ms/step - accuracy: 0.5658 - loss: 0.5815\n",
      "Epoch 13: val_accuracy did not improve from 0.66667\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 750ms/step - accuracy: 0.5664 - loss: 0.5818 - val_accuracy: 0.3889 - val_loss: 1.5332 - learning_rate: 2.0000e-04\n",
      "Epoch 14/25\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 713ms/step - accuracy: 0.5876 - loss: 0.5504\n",
      "Epoch 14: val_accuracy did not improve from 0.66667\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 723ms/step - accuracy: 0.5878 - loss: 0.5510 - val_accuracy: 0.4444 - val_loss: 1.4235 - learning_rate: 2.0000e-04\n",
      "Epoch 15/25\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 717ms/step - accuracy: 0.5693 - loss: 0.5760\n",
      "Epoch 15: val_accuracy did not improve from 0.66667\n",
      "\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 728ms/step - accuracy: 0.5703 - loss: 0.5756 - val_accuracy: 0.5278 - val_loss: 1.4063 - learning_rate: 2.0000e-04\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n"
     ]
    }
   ],
   "source": [
    "# --- Step 6: Train the 1-2 Progression Model ---\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True, verbose=1)\n",
    "model_checkpoint = ModelCheckpoint(MODEL_SAVE_PATH_1_2, save_best_only=True, monitor='val_accuracy', verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-6, verbose=1)\n",
    "print(f\"\\n--- Step 6: Starting Model Training for COPD 1-2 ---\\n\")\n",
    "history_1_2 = model_1_2.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=EPOCHS, batch_size=BATCH_SIZE,\n",
    "    callbacks=[early_stop, model_checkpoint, reduce_lr],\n",
    "    class_weight=class_weights_1_2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "868290aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Step 7: Evaluating Best Saved 1-2 Model ---\n",
      "\n",
      "Final Test Accuracy (1 vs 2): 66.67%\n",
      "Final Test Loss (1 vs 2): 1.0821\n"
     ]
    }
   ],
   "source": [
    "# --- Step 7: Evaluate the Final 1-2 Model ---\n",
    "print(\"\\n--- Step 7: Evaluating Best Saved 1-2 Model ---\")\n",
    "model_1_2.load_weights(MODEL_SAVE_PATH_1_2)\n",
    "loss, accuracy = model_1_2.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"\\nFinal Test Accuracy (1 vs 2): {accuracy*100:.2f}%\")\n",
    "print(f\"Final Test Loss (1 vs 2): {loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7f6fad39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 📈 Starting Analysis for 'COPD2' Patients (Averaging Scores) ---\n",
      "Found 7 patients. Analyzing files...\n",
      "\n",
      "--- ✅ COPD2 Patient Confidence Results (Averaging Method) ---\n",
      "Shows model's confidence in identifying patients known to have Stage 2. Avg_Score >= 0.5 is correct.\n",
      "  Patient ID  Avg_Score  Audio_Files_Found                                       Assessment\n",
      "0       H042   0.923945                 12  ✅ Model Confident (Correctly resembles Stage 2)\n",
      "1       H018   0.927974                 12  ✅ Model Confident (Correctly resembles Stage 2)\n",
      "2       H044   0.942048                 12  ✅ Model Confident (Correctly resembles Stage 2)\n",
      "3       H031   0.942467                 12  ✅ Model Confident (Correctly resembles Stage 2)\n",
      "4       H038   0.950762                 12  ✅ Model Confident (Correctly resembles Stage 2)\n",
      "5       H030   0.957373                 12  ✅ Model Confident (Correctly resembles Stage 2)\n",
      "6       H028   0.966230                 12  ✅ Model Confident (Correctly resembles Stage 2)\n",
      "\n",
      "--- 📈 Starting Analysis for 'COPD1' Patients (Averaging Scores) ---\n",
      "Found 5 patients. Analyzing files...\n",
      "\n",
      "--- ⚠️ COPD1 Patient Progression Risk Results (Averaging Method) ---\n",
      "Shows which Stage 1 patients are flagged as being at high risk of progressing to Stage 2.\n",
      "  Patient ID  Avg_Score  Audio_Files_Found                                         Assessment\n",
      "0       H043   0.952607                 12  ⚠️ High Risk (Resembles Stage 2 - False Positive)\n",
      "1       H039   0.939229                 12  ⚠️ High Risk (Resembles Stage 2 - False Positive)\n",
      "2       H029   0.908344                 12  ⚠️ High Risk (Resembles Stage 2 - False Positive)\n",
      "3       H017   0.891774                 12  ⚠️ High Risk (Resembles Stage 2 - False Positive)\n",
      "4       H045   0.888780                 12  ⚠️ High Risk (Resembles Stage 2 - False Positive)\n"
     ]
    }
   ],
   "source": [
    "# --- Step 8: Patient-Level Analysis (Averaging Method) ---\n",
    "def run_patient_analysis_by_average(trained_model, labels_path, audio_dir, target_diagnosis, sort_ascending):\n",
    "    print(f\"\\n--- 📈 Starting Analysis for '{target_diagnosis}' Patients (Averaging Scores) ---\")\n",
    "    df_labels = pd.read_excel(labels_path)\n",
    "    patient_ids = df_labels[df_labels['Diagnosis'] == target_diagnosis]['Patient ID'].tolist()\n",
    "    if not patient_ids: return None\n",
    "    print(f\"Found {len(patient_ids)} patients. Analyzing files...\")\n",
    "    results_list = []\n",
    "    for pid in patient_ids:\n",
    "        scores = []\n",
    "        for side in ['L', 'R']:\n",
    "            for i in range(1, 7):\n",
    "                fpath = os.path.join(audio_dir, f\"{pid}_{side}{i}.wav\")\n",
    "                if not os.path.exists(fpath): continue\n",
    "                try:\n",
    "                    y, sr = librosa.load(fpath, sr=None)\n",
    "                    spec = extract_log_mel_spectrogram(y, sr)\n",
    "                    prob = trained_model.predict(np.expand_dims(spec, axis=(0, -1)), verbose=0)[0][0]\n",
    "                    scores.append(prob)\n",
    "                except Exception as e:\n",
    "                    print(f\"Warning: Could not process file {fpath}: {e}\")\n",
    "        if scores:\n",
    "            results_list.append({'Patient ID': pid, 'Avg_Score': np.mean(scores), 'Audio_Files_Found': len(scores)})\n",
    "    results_df = pd.DataFrame(results_list).sort_values(by='Avg_Score', ascending=sort_ascending)\n",
    "    return results_df.reset_index(drop=True)\n",
    "\n",
    "def assess_copd2_patient(row):\n",
    "    return \"✅ Model Confident (Correctly resembles Stage 2)\" if row['Avg_Score'] >= 0.5 else \"⚠️ Model Lacks Confidence (False Negative)\"\n",
    "\n",
    "def assess_copd1_progression_risk(row):\n",
    "    return \"⚠️ High Risk (Resembles Stage 2 - False Positive)\" if row['Avg_Score'] >= 0.5 else \"✅ Low Risk (Correctly identified as Stage 1)\"\n",
    "\n",
    "# --- Analyze COPD2 Patients ---\n",
    "copd2_avg_df = run_patient_analysis_by_average(model_1_2, LABEL_PATH_1_2, AUDIO_DIR_1_2, 'COPD2', True)\n",
    "if copd2_avg_df is not None:\n",
    "    copd2_avg_df['Assessment'] = copd2_avg_df.apply(assess_copd2_patient, axis=1)\n",
    "    print(\"\\n--- ✅ COPD2 Patient Confidence Results (Averaging Method) ---\")\n",
    "    print(\"Shows model's confidence in identifying patients known to have Stage 2. Avg_Score >= 0.5 is correct.\")\n",
    "    print(copd2_avg_df.to_string())\n",
    "\n",
    "# --- Analyze COPD1 Patients ---\n",
    "copd1_avg_df = run_patient_analysis_by_average(model_1_2, LABEL_PATH_1_2, AUDIO_DIR_1_2, 'COPD1', False)\n",
    "if copd1_avg_df is not None:\n",
    "    copd1_avg_df['Assessment'] = copd1_avg_df.apply(assess_copd1_progression_risk, axis=1)\n",
    "    print(\"\\n--- ⚠️ COPD1 Patient Progression Risk Results (Averaging Method) ---\")\n",
    "    print(\"Shows which Stage 1 patients are flagged as being at high risk of progressing to Stage 2.\")\n",
    "    print(copd1_avg_df.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c26c5f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e97eb12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e94413be",
   "metadata": {},
   "source": [
    "After data balancing\n",
    "\n",
    "COPD 1 - 5 samples augmented to 6 types\n",
    "\n",
    "COPD 2 - 7 samples augmented to 5 types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "98b977e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Step 3: Loading Data for COPD 1 vs 2 ---\n",
      "\n",
      "Performing stratified patient-aware split...\n",
      "\n",
      "Calculating oversampling rate to balance the training set...\n",
      "Training patient distribution: 4 COPD1, 5 COPD2.\n",
      "Each majority class patient will generate 5 samples.\n",
      "Each minority class patient will generate 6 samples to balance the data.\n",
      "\n",
      "--- Final Data Shapes ---\n",
      " X_train: (588, 128, 150, 1), y_train: (588,)\n",
      " X_test: (36, 128, 150, 1), y_test: (36,)\n",
      "\n",
      "--- Step 4: Verifying Data Balance ---\n",
      "Since we used oversampling, the training data is now manually balanced.\n",
      "Final training sample counts: COPD1(0)=288, COPD2(1)=300\n",
      "Class weights are not needed.\n",
      "\n",
      "--- Step 5: Building the CNN Model for 1-2 Progression ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_3       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> │ input_layer_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>,  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>,  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>,  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ add_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>,  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │ add_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_8     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_11          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ dropout_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │ dropout_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ add_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_22[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_23[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │ add_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_9     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_12          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75776</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │  <span style=\"color: #00af00; text-decoration-color: #00af00\">9,699,456</span> │ flatten_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_13          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ dropout_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_3       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m150\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m1\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_15 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m150\u001b[0m,  │        \u001b[38;5;34m640\u001b[0m │ input_layer_3[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m150\u001b[0m,  │        \u001b[38;5;34m256\u001b[0m │ conv2d_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_16 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m150\u001b[0m,  │     \u001b[38;5;34m36,928\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m150\u001b[0m,  │        \u001b[38;5;34m256\u001b[0m │ conv2d_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_17 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m150\u001b[0m,  │     \u001b[38;5;34m36,928\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m150\u001b[0m,  │        \u001b[38;5;34m256\u001b[0m │ conv2d_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_4 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m150\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_18 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m150\u001b[0m,  │     \u001b[38;5;34m36,928\u001b[0m │ add_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m150\u001b[0m,  │        \u001b[38;5;34m256\u001b[0m │ conv2d_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_19 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m150\u001b[0m,  │     \u001b[38;5;34m36,928\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m150\u001b[0m,  │        \u001b[38;5;34m256\u001b[0m │ conv2d_19[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_5 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m150\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │ add_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_8     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m75\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ add_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_11          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m75\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ max_pooling2d_8[\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_20 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m75\u001b[0m,    │     \u001b[38;5;34m36,928\u001b[0m │ dropout_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m75\u001b[0m,    │        \u001b[38;5;34m256\u001b[0m │ conv2d_20[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_21 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m75\u001b[0m,    │     \u001b[38;5;34m36,928\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m75\u001b[0m,    │        \u001b[38;5;34m256\u001b[0m │ conv2d_21[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_6 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m75\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │ dropout_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_22 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m75\u001b[0m,    │     \u001b[38;5;34m36,928\u001b[0m │ add_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m75\u001b[0m,    │        \u001b[38;5;34m256\u001b[0m │ conv2d_22[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_23 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m75\u001b[0m,    │     \u001b[38;5;34m36,928\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m75\u001b[0m,    │        \u001b[38;5;34m256\u001b[0m │ conv2d_23[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_7 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m75\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │ add_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_9     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m37\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ add_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_12          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m37\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ max_pooling2d_9[\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_3 (\u001b[38;5;33mFlatten\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m75776\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ dropout_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │  \u001b[38;5;34m9,699,456\u001b[0m │ flatten_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_13          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │        \u001b[38;5;34m129\u001b[0m │ dropout_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,997,953</span> (38.14 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m9,997,953\u001b[0m (38.14 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,996,801</span> (38.13 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m9,996,801\u001b[0m (38.13 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,152</span> (4.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,152\u001b[0m (4.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import librosa.effects\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "# --- Step 1: Configuration & Parameters ---\n",
    "LABEL_PATH_1_2 = \"/home/punith/Desktop/cHEAL 2.o/Labels.xlsx\"\n",
    "AUDIO_DIR_1_2 = \"/home/punith/Desktop/cHEAL 2.o/RespiratoryDatabase@TR\"\n",
    "MODEL_SAVE_PATH_1_2 = \"best_copd_1_2_oversampled_model.keras\"\n",
    "\n",
    "N_MELS, MAX_LEN, EPOCHS, BATCH_SIZE = 128, 150, 25, 32\n",
    "NOISE_FACTOR, TIME_SHIFT_MAX_SEC, PITCH_SHIFT_STEPS, TIME_STRETCH_RATE = 0.005, 0.2, 4, 0.8\n",
    "INITIAL_LEARNING_RATE = 0.001\n",
    "\n",
    "\n",
    "# --- Step 2: Helper Functions ---\n",
    "def add_gaussian_noise(y, noise_factor=NOISE_FACTOR): return y + noise_factor * np.random.randn(len(y))\n",
    "def time_shift(y, sr, shift_max_sec=TIME_SHIFT_MAX_SEC): return np.roll(y, int(sr*np.random.uniform(-shift_max_sec, shift_max_sec)))\n",
    "def extract_log_mel_spectrogram(y, sr):\n",
    "    mel_spec = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=N_MELS)\n",
    "    log_mel = librosa.power_to_db(mel_spec)\n",
    "    if log_mel.shape[1] < MAX_LEN: log_mel = np.pad(log_mel, ((0, 0), (0, MAX_LEN - log_mel.shape[1])), mode='constant')\n",
    "    else: log_mel = log_mel[:, :MAX_LEN]\n",
    "    return log_mel\n",
    "\n",
    "\n",
    "# --- Step 3: Load Data and Apply Oversampling to Balance the Dataset ---\n",
    "print(\"--- Step 3: Loading Data for COPD 1 vs 2 ---\")\n",
    "df = pd.read_excel(LABEL_PATH_1_2)\n",
    "df_copd_1_2 = df[df[\"Diagnosis\"].isin([\"COPD1\", \"COPD2\"])].copy()\n",
    "\n",
    "if df_copd_1_2['Diagnosis'].nunique() < 2:\n",
    "    raise ValueError(\"The Excel file must contain patients from both 'COPD1' and 'COPD2'.\")\n",
    "\n",
    "df_copd_1_2['label_encoded'] = df_copd_1_2['Diagnosis'].apply(lambda x: 0 if x == 'COPD1' else 1) # COPD1=0, COPD2=1\n",
    "label_dict_1_2 = dict(zip(df_copd_1_2[\"Patient ID\"], df_copd_1_2[\"label_encoded\"]))\n",
    "patient_ids_1_2 = list(label_dict_1_2.keys())\n",
    "patient_labels_1_2 = list(label_dict_1_2.values())\n",
    "\n",
    "print(\"\\nPerforming stratified patient-aware split...\")\n",
    "try:\n",
    "    train_pids, test_pids, y_train_pids_labels, _ = train_test_split(\n",
    "        patient_ids_1_2, patient_labels_1_2,\n",
    "        test_size=0.25, random_state=42, stratify=patient_labels_1_2\n",
    "    )\n",
    "except ValueError as e:\n",
    "    raise ValueError(f\"\\nFATAL ERROR: {e}\\nThis means a class has only 1 patient.\") from e\n",
    "\n",
    "# --- OVERSAMPLING LOGIC START ---\n",
    "print(\"\\nCalculating oversampling rate to balance the training set...\")\n",
    "base_augmentations = 5\n",
    "num_copd1_train = y_train_pids_labels.count(0)\n",
    "num_copd2_train = y_train_pids_labels.count(1)\n",
    "\n",
    "# Identify which label belongs to the minority class\n",
    "if num_copd1_train < num_copd2_train:\n",
    "    minority_label = 0\n",
    "    minority_count, majority_count = num_copd1_train, num_copd2_train\n",
    "else:\n",
    "    minority_label = 1\n",
    "    minority_count, majority_count = num_copd2_train, num_copd1_train\n",
    "\n",
    "# Calculate how many augmentations are needed for the minority class\n",
    "if minority_count > 0:\n",
    "    oversampling_factor = majority_count / minority_count\n",
    "    augmentations_for_minority = round(base_augmentations * oversampling_factor)\n",
    "else: # Should not happen due to stratify, but good practice\n",
    "    augmentations_for_minority = base_augmentations\n",
    "\n",
    "print(f\"Training patient distribution: {num_copd1_train} COPD1, {num_copd2_train} COPD2.\")\n",
    "print(f\"Each majority class patient will generate {base_augmentations} samples.\")\n",
    "print(f\"Each minority class patient will generate {augmentations_for_minority} samples to balance the data.\")\n",
    "# --- OVERSAMPLING LOGIC END ---\n",
    "\n",
    "X_train, y_train, X_test, y_test = [], [], [], []\n",
    "for pid in patient_ids_1_2:\n",
    "    label = label_dict_1_2[pid]\n",
    "    for side in ['L', 'R']:\n",
    "        for i in range(1, 7):\n",
    "            fpath = os.path.join(AUDIO_DIR_1_2, f\"{pid}_{side}{i}.wav\")\n",
    "            if not os.path.exists(fpath): continue\n",
    "            try:\n",
    "                y_audio, sr = librosa.load(fpath, sr=None)\n",
    "                if pid in train_pids:\n",
    "                    num_augmentations = augmentations_for_minority if label == minority_label else base_augmentations\n",
    "                    y_train.extend([label] * num_augmentations)\n",
    "                    # Create a list of augmented samples. Add more variations if needed.\n",
    "                    augs = [\n",
    "                        extract_log_mel_spectrogram(y_audio, sr),\n",
    "                        extract_log_mel_spectrogram(add_gaussian_noise(y_audio), sr),\n",
    "                        extract_log_mel_spectrogram(time_shift(y_audio, sr), sr),\n",
    "                        extract_log_mel_spectrogram(librosa.effects.pitch_shift(y=y_audio, sr=sr, n_steps=PITCH_SHIFT_STEPS), sr),\n",
    "                        extract_log_mel_spectrogram(librosa.effects.time_stretch(y=y_audio, rate=1/TIME_STRETCH_RATE), sr),\n",
    "                        # Add more augmentations to draw from if needed for high oversampling rates\n",
    "                        extract_log_mel_spectrogram(librosa.effects.pitch_shift(y=y_audio, sr=sr, n_steps=-PITCH_SHIFT_STEPS), sr),\n",
    "                        extract_log_mel_spectrogram(time_shift(y_audio, sr), sr) # another random time shift\n",
    "                    ]\n",
    "                    X_train.extend(augs[:num_augmentations])\n",
    "                elif pid in test_pids:\n",
    "                    X_test.append(extract_log_mel_spectrogram(y_audio, sr))\n",
    "                    y_test.append(label)\n",
    "            except Exception as e:\n",
    "                print(f\"Warning: Error processing {fpath}: {e}\")\n",
    "\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "X_test, y_test = np.array(X_test), np.array(y_test)\n",
    "if len(np.unique(y_train)) < 2: raise ValueError(f\"FATAL: Training set has <2 classes due to MISSING audio files in '{AUDIO_DIR_1_2}'.\")\n",
    "X_train, X_test = X_train[..., np.newaxis], X_test[..., np.newaxis]\n",
    "print(\"\\n--- Final Data Shapes ---\\n\", f\"X_train: {X_train.shape}, y_train: {y_train.shape}\\n\", f\"X_test: {X_test.shape}, y_test: {y_test.shape}\")\n",
    "\n",
    "# --- Step 4: Verify Class Balance ---\n",
    "print(\"\\n--- Step 4: Verifying Data Balance ---\")\n",
    "print(\"Since we used oversampling, the training data is now manually balanced.\")\n",
    "print(f\"Final training sample counts: COPD1(0)={np.sum(y_train == 0)}, COPD2(1)={np.sum(y_train == 1)}\")\n",
    "print(\"Class weights are not needed.\")\n",
    "\n",
    "\n",
    "# --- Step 5: Build the CNN Model ---\n",
    "print(\"\\n--- Step 5: Building the CNN Model for 1-2 Progression ---\")\n",
    "# model_1_2 = Sequential([\n",
    "#     tf.keras.Input(shape=(N_MELS, MAX_LEN, 1)),\n",
    "#     Conv2D(32, (3, 3), activation='relu', padding='same'), BatchNormalization(),\n",
    "#     MaxPooling2D(pool_size=(2, 2)), Dropout(0.3),\n",
    "#     Conv2D(64, (3, 3), activation='relu', padding='same'), BatchNormalization(),\n",
    "#     MaxPooling2D(pool_size=(2, 2)), Dropout(0.3),\n",
    "#     Conv2D(128, (3, 3), activation='relu', padding='same'), BatchNormalization(),\n",
    "#     MaxPooling2D(pool_size=(2, 2)), Dropout(0.3),\n",
    "#     Flatten(), Dense(128, activation='relu'), Dropout(0.5),\n",
    "#     Dense(1, activation='sigmoid')\n",
    "# ])\n",
    "# model_1_2.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=INITIAL_LEARNING_RATE), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# model_1_2.summary()\n",
    "\n",
    "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, MaxPooling2D, Dropout, Flatten, Dense, Add\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def resnet_block(input_tensor, filters):\n",
    "    \"\"\"A simple residual block.\"\"\"\n",
    "    x = Conv2D(filters, (3, 3), activation='relu', padding='same')(input_tensor)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(filters, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    # This is the \"skip connection\"\n",
    "    # It adds the original input back to the output of the convolutional block\n",
    "    x = Add()([x, input_tensor])\n",
    "    return x\n",
    "\n",
    "# --- Define the Model Architecture using the ResNet block ---\n",
    "input_layer = Input(shape=(N_MELS, MAX_LEN, 1))\n",
    "\n",
    "# Initial Conv layer to get to the right number of filters (e.g., 64)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(input_layer)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "# --- Add Residual Blocks ---\n",
    "x = resnet_block(x, filters=64)\n",
    "x = resnet_block(x, filters=64)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = Dropout(0.3)(x)\n",
    "\n",
    "x = resnet_block(x, filters=64)\n",
    "x = resnet_block(x, filters=64)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = Dropout(0.3)(x)\n",
    "\n",
    "# --- Classifier Head ---\n",
    "x = Flatten()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "output_layer = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "# Create the final model\n",
    "model_1_2_resnet = Model(inputs=input_layer, outputs=output_layer)\n",
    "model_1_2_resnet.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=INITIAL_LEARNING_RATE), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model_1_2_resnet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "eda513b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Step 6: Starting Model Training on Balanced Data ---\n",
      "\n",
      "Epoch 1/25\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 648ms/step - accuracy: 0.6401 - loss: 0.5192\n",
      "Epoch 1: val_accuracy improved from -inf to 0.41667, saving model to best_copd_1_2_oversampled_model.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 669ms/step - accuracy: 0.6412 - loss: 0.5179 - val_accuracy: 0.4167 - val_loss: 0.8251 - learning_rate: 0.0010\n",
      "Epoch 2/25\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 663ms/step - accuracy: 0.7133 - loss: 0.4757\n",
      "Epoch 2: val_accuracy improved from 0.41667 to 0.44444, saving model to best_copd_1_2_oversampled_model.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 684ms/step - accuracy: 0.7144 - loss: 0.4749 - val_accuracy: 0.4444 - val_loss: 1.0353 - learning_rate: 0.0010\n",
      "Epoch 3/25\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 667ms/step - accuracy: 0.8180 - loss: 0.3689\n",
      "Epoch 3: val_accuracy improved from 0.44444 to 0.55556, saving model to best_copd_1_2_oversampled_model.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 687ms/step - accuracy: 0.8165 - loss: 0.3705 - val_accuracy: 0.5556 - val_loss: 0.9790 - learning_rate: 0.0010\n",
      "Epoch 4/25\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 669ms/step - accuracy: 0.7863 - loss: 0.3574\n",
      "Epoch 4: val_accuracy did not improve from 0.55556\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 678ms/step - accuracy: 0.7855 - loss: 0.3581 - val_accuracy: 0.4722 - val_loss: 1.1279 - learning_rate: 0.0010\n",
      "Epoch 5/25\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 685ms/step - accuracy: 0.7697 - loss: 0.3541\n",
      "Epoch 5: val_accuracy did not improve from 0.55556\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 694ms/step - accuracy: 0.7702 - loss: 0.3532 - val_accuracy: 0.3889 - val_loss: 1.7204 - learning_rate: 0.0010\n",
      "Epoch 6/25\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 660ms/step - accuracy: 0.8145 - loss: 0.3285\n",
      "Epoch 6: val_accuracy did not improve from 0.55556\n",
      "\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 668ms/step - accuracy: 0.8137 - loss: 0.3295 - val_accuracy: 0.3889 - val_loss: 1.4606 - learning_rate: 0.0010\n",
      "Epoch 7/25\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 670ms/step - accuracy: 0.7829 - loss: 0.3229\n",
      "Epoch 7: val_accuracy did not improve from 0.55556\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 680ms/step - accuracy: 0.7844 - loss: 0.3216 - val_accuracy: 0.3889 - val_loss: 1.7226 - learning_rate: 2.0000e-04\n",
      "Epoch 8/25\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 687ms/step - accuracy: 0.8064 - loss: 0.2915\n",
      "Epoch 8: val_accuracy did not improve from 0.55556\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 696ms/step - accuracy: 0.8072 - loss: 0.2910 - val_accuracy: 0.4167 - val_loss: 1.8940 - learning_rate: 2.0000e-04\n",
      "Epoch 9/25\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 669ms/step - accuracy: 0.8186 - loss: 0.2868\n",
      "Epoch 9: val_accuracy did not improve from 0.55556\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 678ms/step - accuracy: 0.8192 - loss: 0.2860 - val_accuracy: 0.3889 - val_loss: 1.9458 - learning_rate: 2.0000e-04\n",
      "Epoch 10/25\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 701ms/step - accuracy: 0.8304 - loss: 0.2720\n",
      "Epoch 10: val_accuracy did not improve from 0.55556\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 711ms/step - accuracy: 0.8307 - loss: 0.2711 - val_accuracy: 0.4167 - val_loss: 2.2071 - learning_rate: 2.0000e-04\n",
      "Epoch 11/25\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 692ms/step - accuracy: 0.8675 - loss: 0.2367\n",
      "Epoch 11: val_accuracy did not improve from 0.55556\n",
      "\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 701ms/step - accuracy: 0.8670 - loss: 0.2371 - val_accuracy: 0.4167 - val_loss: 2.4048 - learning_rate: 2.0000e-04\n",
      "Epoch 11: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n"
     ]
    }
   ],
   "source": [
    "# --- Step 6: Train the Model ---\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True, verbose=1)\n",
    "model_checkpoint = ModelCheckpoint(MODEL_SAVE_PATH_1_2, save_best_only=True, monitor='val_accuracy', verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-6, verbose=1)\n",
    "print(f\"\\n--- Step 6: Starting Model Training on Balanced Data ---\\n\")\n",
    "# We DO NOT pass class_weight here, as the data is already balanced\n",
    "history_1_2 = model_1_2.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=EPOCHS, batch_size=BATCH_SIZE, callbacks=[early_stop, model_checkpoint, reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "81aa604e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Step 7: Evaluating Best Saved Model ---\n",
      "\n",
      "Final Test Accuracy (1 vs 2): 55.56%\n",
      "Final Test Loss (1 vs 2): 0.9790\n"
     ]
    }
   ],
   "source": [
    "# --- Step 7: Evaluate the Final Model ---\n",
    "print(\"\\n--- Step 7: Evaluating Best Saved Model ---\")\n",
    "model_1_2.load_weights(MODEL_SAVE_PATH_1_2)\n",
    "loss, accuracy = model_1_2.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"\\nFinal Test Accuracy (1 vs 2): {accuracy*100:.2f}%\")\n",
    "print(f\"Final Test Loss (1 vs 2): {loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "678c1f76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 📈 Starting Analysis for 'COPD2' Patients (Averaging Scores) ---\n",
      "Found 7 patients. Analyzing files...\n",
      "  -> Raw Scores for Patient H018: ['0.9585', '0.9930', '0.9683', '0.9209', '0.9946', '0.9794', '0.9402', '0.9764', '0.9738', '0.9938', '0.9898', '0.9981']\n",
      "  -> Raw Scores for Patient H028: ['0.8745', '0.9564', '0.9635', '0.9132', '0.8788', '0.8706', '0.9170', '0.8631', '0.9199', '0.8957', '0.6491', '0.9875']\n",
      "  -> Raw Scores for Patient H030: ['0.9761', '0.9740', '0.9293', '0.5022', '0.8417', '0.8656', '0.9631', '0.8492', '0.9919', '0.6016', '0.8483', '0.9950']\n",
      "  -> Raw Scores for Patient H031: ['0.9976', '0.9738', '0.8924', '0.8240', '0.9142', '0.6711', '0.9747', '0.9812', '0.9916', '0.8795', '0.9794', '0.7426']\n",
      "  -> Raw Scores for Patient H038: ['0.7748', '0.5026', '0.0402', '0.7305', '0.0451', '0.8181', '0.1601', '0.1640', '0.3982', '0.4474', '0.6468', '0.3387']\n",
      "  -> Raw Scores for Patient H042: ['0.9131', '0.9477', '0.9030', '0.8864', '0.9581', '0.8764', '0.9623', '0.7627', '0.9594', '0.7406', '0.9312', '0.6214']\n",
      "  -> Raw Scores for Patient H044: ['0.9923', '0.9551', '0.5081', '0.7450', '0.9919', '0.5494', '0.9651', '0.9757', '0.3729', '0.9304', '0.9636', '0.5904']\n",
      "\n",
      "--- ✅ COPD2 Patient Confidence Results (Averaging Method) ---\n",
      "Shows model's confidence in identifying patients known to have Stage 2. Avg_Score >= 0.5 is correct.\n",
      "  Patient ID  Avg_Score  Audio_Files_Found                                       Assessment\n",
      "0       H038   0.422212                 12       ⚠️ Model Lacks Confidence (False Negative)\n",
      "1       H044   0.795004                 12  ✅ Model Confident (Correctly resembles Stage 2)\n",
      "2       H030   0.861504                 12  ✅ Model Confident (Correctly resembles Stage 2)\n",
      "3       H042   0.871859                 12  ✅ Model Confident (Correctly resembles Stage 2)\n",
      "4       H028   0.890779                 12  ✅ Model Confident (Correctly resembles Stage 2)\n",
      "5       H031   0.901851                 12  ✅ Model Confident (Correctly resembles Stage 2)\n",
      "6       H018   0.973894                 12  ✅ Model Confident (Correctly resembles Stage 2)\n",
      "\n",
      "--- 📈 Starting Analysis for 'COPD1' Patients (Averaging Scores) ---\n",
      "Found 5 patients. Analyzing files...\n",
      "  -> Raw Scores for Patient H017: ['0.3877', '0.4607', '0.0382', '0.7224', '0.0553', '0.4722', '0.2890', '0.0561', '0.6381', '0.5801', '0.0115', '0.1480']\n",
      "  -> Raw Scores for Patient H029: ['0.0049', '0.0028', '0.4107', '0.0622', '0.0486', '0.4169', '0.0010', '0.0061', '0.0713', '0.3557', '0.0952', '0.4776']\n",
      "  -> Raw Scores for Patient H039: ['0.1734', '0.0577', '0.3457', '0.2395', '0.2054', '0.0388', '0.2233', '0.1967', '0.2831', '0.5582', '0.1500', '0.1923']\n",
      "  -> Raw Scores for Patient H043: ['0.6287', '0.3501', '0.9033', '0.8244', '0.9196', '0.6221', '0.7842', '0.4251', '0.8376', '0.4475', '0.9625', '0.3957']\n",
      "  -> Raw Scores for Patient H045: ['0.0109', '0.0363', '0.1328', '0.1677', '0.0125', '0.1502', '0.0093', '0.0859', '0.0804', '0.2837', '0.0049', '0.0336']\n",
      "\n",
      "--- ⚠️ COPD1 Patient Progression Risk Results (Averaging Method) ---\n",
      "Shows which Stage 1 patients are flagged as being at high risk of progressing to Stage 2.\n",
      "  Patient ID  Avg_Score  Audio_Files_Found                                         Assessment\n",
      "0       H043   0.675082                 12  ⚠️ High Risk (Resembles Stage 2 - False Positive)\n",
      "1       H017   0.321610                 12       ✅ Low Risk (Correctly identified as Stage 1)\n",
      "2       H039   0.222016                 12       ✅ Low Risk (Correctly identified as Stage 1)\n",
      "3       H029   0.162745                 12       ✅ Low Risk (Correctly identified as Stage 1)\n",
      "4       H045   0.084028                 12       ✅ Low Risk (Correctly identified as Stage 1)\n"
     ]
    }
   ],
   "source": [
    "# --- Step 8: Patient-Level Analysis (Averaging Method with Detailed Scores) ---\n",
    "\n",
    "def run_patient_analysis_by_average(trained_model, labels_path, audio_dir, target_diagnosis, sort_ascending):\n",
    "    \"\"\"\n",
    "    Analyzes patients by averaging scores and also shows the raw prediction\n",
    "    for each of the 12 audio files per patient.\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- 📈 Starting Analysis for '{target_diagnosis}' Patients (Averaging Scores) ---\")\n",
    "    df_labels = pd.read_excel(labels_path)\n",
    "    patient_ids = df_labels[df_labels['Diagnosis'] == target_diagnosis]['Patient ID'].tolist()\n",
    "    if not patient_ids: return None\n",
    "    print(f\"Found {len(patient_ids)} patients. Analyzing files...\")\n",
    "    results_list = []\n",
    "    for pid in patient_ids:\n",
    "        scores = []\n",
    "        for side in ['L', 'R']:\n",
    "            for i in range(1, 7):\n",
    "                fpath = os.path.join(audio_dir, f\"{pid}_{side}{i}.wav\")\n",
    "                if not os.path.exists(fpath): continue\n",
    "                try:\n",
    "                    y, sr = librosa.load(fpath, sr=None)\n",
    "                    spec = extract_log_mel_spectrogram(y, sr)\n",
    "                    prob = trained_model.predict(np.expand_dims(spec, axis=(0, -1)), verbose=0)[0][0]\n",
    "                    scores.append(prob)\n",
    "                except Exception as e:\n",
    "                    print(f\"Warning: Could not process file {fpath}: {e}\")\n",
    "\n",
    "        # If any scores were successfully collected for the patient:\n",
    "        if scores:\n",
    "            # --- ADDITION: Print the detailed scores for this patient ---\n",
    "            formatted_scores = [f'{s:.4f}' for s in scores]\n",
    "            print(f\"  -> Raw Scores for Patient {pid}: {formatted_scores}\")\n",
    "            \n",
    "            # Append the calculated average to the results list\n",
    "            results_list.append({'Patient ID': pid, 'Avg_Score': np.mean(scores), 'Audio_Files_Found': len(scores)})\n",
    "            \n",
    "    # If no results were generated at all, exit.\n",
    "    if not results_list:\n",
    "        print(\"Could not generate any analysis results. Check if audio files exist.\")\n",
    "        return None\n",
    "\n",
    "    results_df = pd.DataFrame(results_list).sort_values(by='Avg_Score', ascending=sort_ascending)\n",
    "    return results_df.reset_index(drop=True)\n",
    "\n",
    "# Assessment functions remain the same\n",
    "def assess_copd2_patient(row):\n",
    "    return \"✅ Model Confident (Correctly resembles Stage 2)\" if row['Avg_Score'] >= 0.5 else \"⚠️ Model Lacks Confidence (False Negative)\"\n",
    "\n",
    "def assess_copd1_progression_risk(row):\n",
    "    return \"⚠️ High Risk (Resembles Stage 2 - False Positive)\" if row['Avg_Score'] >= 0.5 else \"✅ Low Risk (Correctly identified as Stage 1)\"\n",
    "\n",
    "# --- Run Analysis for COPD2 Patients ---\n",
    "copd2_avg_df = run_patient_analysis_by_average(model_1_2, LABEL_PATH_1_2, AUDIO_DIR_1_2, 'COPD2', True)\n",
    "if copd2_avg_df is not None:\n",
    "    copd2_avg_df['Assessment'] = copd2_avg_df.apply(assess_copd2_patient, axis=1)\n",
    "    print(\"\\n--- ✅ COPD2 Patient Confidence Results (Averaging Method) ---\")\n",
    "    print(\"Shows model's confidence in identifying patients known to have Stage 2. Avg_Score >= 0.5 is correct.\")\n",
    "    print(copd2_avg_df.to_string())\n",
    "\n",
    "# --- Run Analysis for COPD1 Patients ---\n",
    "copd1_avg_df = run_patient_analysis_by_average(model_1_2, LABEL_PATH_1_2, AUDIO_DIR_1_2, 'COPD1', False)\n",
    "if copd1_avg_df is not None:\n",
    "    copd1_avg_df['Assessment'] = copd1_avg_df.apply(assess_copd1_progression_risk, axis=1)\n",
    "    print(\"\\n--- ⚠️ COPD1 Patient Progression Risk Results (Averaging Method) ---\")\n",
    "    print(\"Shows which Stage 1 patients are flagged as being at high risk of progressing to Stage 2.\")\n",
    "    print(copd1_avg_df.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "290ca19b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 🗳️ Starting Analysis for 'COPD2' Patients (Majority Vote) ---\n",
      "Found 7 patients. Analyzing files and counting votes...\n",
      "  -> Raw Scores for Patient H018: ['0.9585', '0.9930', '0.9683', '0.9209', '0.9946', '0.9794', '0.9402', '0.9764', '0.9738', '0.9938', '0.9898', '0.9981']\n",
      "  -> Raw Scores for Patient H028: ['0.8745', '0.9564', '0.9635', '0.9132', '0.8788', '0.8706', '0.9170', '0.8631', '0.9199', '0.8957', '0.6491', '0.9875']\n",
      "  -> Raw Scores for Patient H030: ['0.9761', '0.9740', '0.9293', '0.5022', '0.8417', '0.8656', '0.9631', '0.8492', '0.9919', '0.6016', '0.8483', '0.9950']\n",
      "  -> Raw Scores for Patient H031: ['0.9976', '0.9738', '0.8924', '0.8240', '0.9142', '0.6711', '0.9747', '0.9812', '0.9916', '0.8795', '0.9794', '0.7426']\n",
      "  -> Raw Scores for Patient H038: ['0.7748', '0.5026', '0.0402', '0.7305', '0.0451', '0.8181', '0.1601', '0.1640', '0.3982', '0.4474', '0.6468', '0.3387']\n",
      "  -> Raw Scores for Patient H042: ['0.9131', '0.9477', '0.9030', '0.8864', '0.9581', '0.8764', '0.9623', '0.7627', '0.9594', '0.7406', '0.9312', '0.6214']\n",
      "  -> Raw Scores for Patient H044: ['0.9923', '0.9551', '0.5081', '0.7450', '0.9919', '0.5494', '0.9651', '0.9757', '0.3729', '0.9304', '0.9636', '0.5904']\n",
      "\n",
      "--- ✅ COPD2 Patient Majority Vote Results ---\n",
      "This table shows if the model's majority vote matched the patient's actual 'COPD2' diagnosis.\n",
      "  Patient ID  COPD2_Votes  COPD1_Votes  Total_Files Final_Prediction                                    Assessment\n",
      "0       H038            5            7           12            COPD1  ❌ Incorrect (Predicted COPD1, but was COPD2)\n",
      "1       H044           11            1           12            COPD2                   ✅ Correct (Predicted COPD2)\n",
      "2       H018           12            0           12            COPD2                   ✅ Correct (Predicted COPD2)\n",
      "3       H028           12            0           12            COPD2                   ✅ Correct (Predicted COPD2)\n",
      "4       H031           12            0           12            COPD2                   ✅ Correct (Predicted COPD2)\n",
      "5       H030           12            0           12            COPD2                   ✅ Correct (Predicted COPD2)\n",
      "6       H042           12            0           12            COPD2                   ✅ Correct (Predicted COPD2)\n",
      "\n",
      "--- 🗳️ Starting Analysis for 'COPD1' Patients (Majority Vote) ---\n",
      "Found 5 patients. Analyzing files and counting votes...\n",
      "  -> Raw Scores for Patient H017: ['0.3877', '0.4607', '0.0382', '0.7224', '0.0553', '0.4722', '0.2890', '0.0561', '0.6381', '0.5801', '0.0115', '0.1480']\n",
      "  -> Raw Scores for Patient H029: ['0.0049', '0.0028', '0.4107', '0.0622', '0.0486', '0.4169', '0.0010', '0.0061', '0.0713', '0.3557', '0.0952', '0.4776']\n",
      "  -> Raw Scores for Patient H039: ['0.1734', '0.0577', '0.3457', '0.2395', '0.2054', '0.0388', '0.2233', '0.1967', '0.2831', '0.5582', '0.1500', '0.1923']\n",
      "  -> Raw Scores for Patient H043: ['0.6287', '0.3501', '0.9033', '0.8244', '0.9196', '0.6221', '0.7842', '0.4251', '0.8376', '0.4475', '0.9625', '0.3957']\n",
      "  -> Raw Scores for Patient H045: ['0.0109', '0.0363', '0.1328', '0.1677', '0.0125', '0.1502', '0.0093', '0.0859', '0.0804', '0.2837', '0.0049', '0.0336']\n",
      "\n",
      "--- ⚠️ COPD1 Patient Progression Risk Results ---\n",
      "This table shows if a Stage 1 patient is incorrectly flagged as having progressed to Stage 2.\n",
      "Incorrect '❌' assessments here are patients the model thinks are at HIGH RISK of progression.\n",
      "  Patient ID  COPD2_Votes  COPD1_Votes  Total_Files Final_Prediction                                    Assessment\n",
      "0       H043            8            4           12            COPD2  ❌ Incorrect (Predicted COPD2, but was COPD1)\n",
      "1       H017            3            9           12            COPD1                   ✅ Correct (Predicted COPD1)\n",
      "2       H039            1           11           12            COPD1                   ✅ Correct (Predicted COPD1)\n",
      "3       H029            0           12           12            COPD1                   ✅ Correct (Predicted COPD1)\n",
      "4       H045            0           12           12            COPD1                   ✅ Correct (Predicted COPD1)\n"
     ]
    }
   ],
   "source": [
    "# --- Step 8: Patient-Level Analysis (Counting Method with Detailed Scores) ---\n",
    "\n",
    "def run_patient_analysis_by_vote(trained_model, labels_path, audio_dir, target_diagnosis, sort_ascending):\n",
    "    \"\"\"\n",
    "    Analyzes patients using a majority vote method. It first shows the raw\n",
    "    prediction for each audio file, then counts the votes to determine the\n",
    "    final patient-level prediction.\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- 🗳️ Starting Analysis for '{target_diagnosis}' Patients (Majority Vote) ---\")\n",
    "    df_labels = pd.read_excel(labels_path)\n",
    "    patient_ids = df_labels[df_labels['Diagnosis'] == target_diagnosis]['Patient ID'].tolist()\n",
    "    if not patient_ids: return None\n",
    "    print(f\"Found {len(patient_ids)} patients. Analyzing files and counting votes...\")\n",
    "    \n",
    "    patient_scores_data = {}\n",
    "    for pid in patient_ids:\n",
    "        scores = []\n",
    "        for side in ['L', 'R']:\n",
    "            for i in range(1, 7):\n",
    "                fpath = os.path.join(audio_dir, f\"{pid}_{side}{i}.wav\")\n",
    "                if not os.path.exists(fpath): continue\n",
    "                try:\n",
    "                    y, sr = librosa.load(fpath, sr=None)\n",
    "                    spec = extract_log_mel_spectrogram(y, sr)\n",
    "                    prob = trained_model.predict(np.expand_dims(spec, axis=(0, -1)), verbose=0)[0][0]\n",
    "                    scores.append(prob)\n",
    "                except Exception as e:\n",
    "                    print(f\"Warning: Could not process file {fpath}: {e}\")\n",
    "        \n",
    "        # If scores were collected, show the details and store them\n",
    "        if scores:\n",
    "            # --- ADDITION: Print the detailed scores for this patient ---\n",
    "            formatted_scores = [f'{s:.4f}' for s in scores]\n",
    "            print(f\"  -> Raw Scores for Patient {pid}: {formatted_scores}\")\n",
    "            \n",
    "            patient_scores_data[pid] = scores\n",
    "\n",
    "    # If no patient data could be processed, exit.\n",
    "    if not patient_scores_data:\n",
    "        print(\"Could not generate any analysis results. Check if audio files exist.\")\n",
    "        return None\n",
    "        \n",
    "    results_list = []\n",
    "    for pid, scores in patient_scores_data.items():\n",
    "        # --- COUNTING LOGIC ---\n",
    "        copd2_votes = sum(1 for s in scores if s >= 0.5)\n",
    "        copd1_votes = len(scores) - copd2_votes\n",
    "        \n",
    "        # Determine final prediction by majority (defaulting to Stage 1 on a tie)\n",
    "        final_prediction = 'COPD2' if copd2_votes > copd1_votes else 'COPD1'\n",
    "            \n",
    "        results_list.append({\n",
    "            'Patient ID': pid, 'COPD2_Votes': copd2_votes, 'COPD1_Votes': copd1_votes,\n",
    "            'Total_Files': len(scores), 'Final_Prediction': final_prediction\n",
    "        })\n",
    "\n",
    "    results_df = pd.DataFrame(results_list).sort_values(by='COPD2_Votes', ascending=sort_ascending)\n",
    "    return results_df.reset_index(drop=True)\n",
    "\n",
    "def assess_prediction_vs_truth(row, true_label):\n",
    "    \"\"\"Compares the majority vote prediction to the known truth.\"\"\"\n",
    "    if row['Final_Prediction'] == true_label:\n",
    "        return f\"✅ Correct (Predicted {row['Final_Prediction']})\"\n",
    "    else:\n",
    "        return f\"❌ Incorrect (Predicted {row['Final_Prediction']}, but was {true_label})\"\n",
    "\n",
    "\n",
    "# --- Run Analysis on COPD2 Patients (High-Severity Group) ---\n",
    "copd2_vote_df = run_patient_analysis_by_vote(\n",
    "    trained_model=model_1_2, labels_path=LABEL_PATH_1_2, audio_dir=AUDIO_DIR_1_2,\n",
    "    target_diagnosis='COPD2', sort_ascending=True # Show patients with FEWEST votes for COPD2 first\n",
    ")\n",
    "if copd2_vote_df is not None:\n",
    "    copd2_vote_df['Assessment'] = copd2_vote_df.apply(assess_prediction_vs_truth, true_label='COPD2', axis=1)\n",
    "    print(\"\\n--- ✅ COPD2 Patient Majority Vote Results ---\")\n",
    "    print(\"This table shows if the model's majority vote matched the patient's actual 'COPD2' diagnosis.\")\n",
    "    print(copd2_vote_df.to_string())\n",
    "\n",
    "# --- Run Analysis on COPD1 Patients (Progression Risk Group) ---\n",
    "copd1_vote_df = run_patient_analysis_by_vote(\n",
    "    trained_model=model_1_2, labels_path=LABEL_PATH_1_2, audio_dir=AUDIO_DIR_1_2,\n",
    "    target_diagnosis='COPD1', sort_ascending=False # Show Stage 1 patients with MOST votes for COPD2 first\n",
    ")\n",
    "if copd1_vote_df is not None:\n",
    "    copd1_vote_df['Assessment'] = copd1_vote_df.apply(assess_prediction_vs_truth, true_label='COPD1', axis=1)\n",
    "    print(\"\\n--- ⚠️ COPD1 Patient Progression Risk Results ---\")\n",
    "    print(\"This table shows if a Stage 1 patient is incorrectly flagged as having progressed to Stage 2.\")\n",
    "    print(\"Incorrect '❌' assessments here are patients the model thinks are at HIGH RISK of progression.\")\n",
    "    print(copd1_vote_df.to_string())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "audio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
